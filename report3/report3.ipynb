{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データマイニング Report3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 全体の流れ\n",
    "    + NLTKの解説本の0章〜12章まで、計13個のHTMLファイルをダウンロードせよ。\n",
    "    + BoWベースの特徴ベクトル（Level 1 もしくは Level 2）を生成せよ。\n",
    "    + 共起行列ベースの特徴ベクトル（Level3）を生成せよ。\n",
    "    + ラベル付き文書に対して分類タスク（Level4）を実行せよ。\n",
    "+ Level 1: 文書ファイル毎に、``Bag-of-Words``で特徴ベクトルを生成せよ。\n",
    "+ Level 2: ``BoW``に``TF-IDF``で重み調整した特徴ベクトルを生成せよ。\n",
    "+ Level 3: 単語の``共起行列``から特徴ベクトルを生成せよ。\n",
    "+ Level 4: ``文書分類``せよ。\n",
    "+ オプション例\n",
    "    + 相互情報量から``特徴ベクトル``を生成してみよう。\n",
    "    + 共起行列に基づいた特徴ベクトル、もしくは相互特徴量に基づいた特徴ベクトルを``SVD``により``次元削減``してみよう。\n",
    "    + SVDによる次元削減時に``2次元``とせよ。気になる単語1つを選び、上位10件と下位10件を2次元空間にマッピングせよ。マッピング結果、どのように散らばっているか観察し、想定とどのぐらい似通っているか考察してみよう。\n",
    "    + ``日本語文書``について自然言語処理してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.spatial.distance as distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ collect_words_eng(): 英文書集合から単語コードブック作成\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltkのdownloadするべきmoudle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/e175751/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/e175751/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/e175751/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文書集合からターム素性集合（コードブック）を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_words_eng(docs):\n",
    "    '''\n",
    "    英文書集合から単語コードブック作成。\n",
    "    シンプルに文書集合を予め決めうちした方式で処理する。\n",
    "    必要に応じて指定できるようにしていた方が使い易いかも。\n",
    "\n",
    "    :param docs(list): 1文書1文字列で保存。複数文書をリストとして並べたもの。\n",
    "    :return (list): 文分割、単語分割、基本形、ストップワード除去した、ユニークな単語一覧。\n",
    "    '''\n",
    "    \n",
    "    codebook = []\n",
    "    stopwords = nltk.corpus.stopwords.words('english') \n",
    "    \n",
    "    #stopwords.append('.')   # ピリオドを追加。\n",
    "    #stopwords.append(',')   # カンマを追加。\n",
    "    #stopwords.append('')    # 空文字を追加。\n",
    "    \n",
    "    symbol = [\"'\", '\"', ':', ';', '.', ',', '-', '!', '?', \"'s\"]\n",
    "    clean_frequency = nltk.FreqDist(w.lower() for w in docs if w.lower() not in stopwords + symbol)\n",
    "    \n",
    "    wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    \n",
    "    for doc in docs:\n",
    "        for sent in sent_tokenize(doc):\n",
    "            for word in wordpunct_tokenize(sent):\n",
    "                this_word = wnl.lemmatize(word.lower())\n",
    "                if this_word not in codebook and this_word not in clean_frequency:\n",
    "                    codebook.append(this_word)\n",
    "    return codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``clean_frequencya``を使った場合\n",
    "これにより、vector数が10個になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs3 = []\n",
    "docs3.append(\"This is test.\")\n",
    "docs3.append(\"That is test too.\")\n",
    "docs3.append(\"There are so many many tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codebook =  ['this', 'is', 'test', '.', 'that', 'too', 'there', 'are', 'so', 'many']\n"
     ]
    }
   ],
   "source": [
    "codebook = collect_words_eng(docs3)\n",
    "print('codebook = ',codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``stopwords``のままの場合\n",
    "これにより、vector数が2個となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codebook =  ['test', 'many']\n"
     ]
    }
   ],
   "source": [
    "codebook = collect_words_eng(docs3)\n",
    "print('codebook = ',codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードブックを素性とする文書ベクトルを作る (直接ベクトル生成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vectors_eng(docs, codebook):\n",
    "    '''コードブックを素性とする文書ベクトルを作る（直接ベクトル生成）\n",
    "\n",
    "    :param docs(list): 1文書1文字列で保存。複数文書をリストとして並べたもの。\n",
    "    :param codebook(list): ユニークな単語一覧。\n",
    "    :return (list): コードブックを元に、出現回数を特徴量とするベクトルを返す。\n",
    "    '''\n",
    "    vectors = []\n",
    "    wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    for doc in docs:\n",
    "        this_vector = []\n",
    "        fdist = nltk.FreqDist()\n",
    "        for sent in sent_tokenize(doc):\n",
    "            for word in wordpunct_tokenize(sent):\n",
    "                this_word = wnl.lemmatize(word.lower())\n",
    "                fdist[this_word] += 1\n",
    "        for word in codebook:\n",
    "            this_vector.append(fdist[word])\n",
    "        vectors.append(this_vector)\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs[0] = This is test.\n",
      "vectors[0] = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "----\n",
      "docs[1] = That is test too.\n",
      "vectors[1] = [0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "----\n",
      "docs[2] = There are so many many tests.\n",
      "vectors[2] = [0, 0, 1, 1, 0, 0, 1, 1, 1, 2]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "vectors = make_vectors_eng(docs3, codebook)\n",
    "for index in range(len(docs3)):\n",
    "    print('docs[{}] = {}'.format(index,docs3[index]))\n",
    "    print('vectors[{}] = {}'.format(index,vectors[index]))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユークリッド距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    vectors = np.array(vectors)\n",
    "    distances = []\n",
    "    for i in range(len(vectors)):\n",
    "        temp = []\n",
    "        for j in range(len(vectors)):\n",
    "            temp.append(np.linalg.norm(vectors[i] - vectors[j]))\n",
    "        distances.append(temp)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# euclidean_distance\n",
      "[0.0, 1.7320508075688772, 3.0]\n",
      "[1.7320508075688772, 0.0, 3.1622776601683795]\n",
      "[3.0, 3.1622776601683795, 0.0]\n"
     ]
    }
   ],
   "source": [
    "distances = euclidean_distance(vectors)\n",
    "print('# euclidean_distance')\n",
    "for index in range(len(distances)):\n",
    "    print(distances[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vectors):\n",
    "    vectors = np.array(vectors)\n",
    "    distances = []\n",
    "    for i in range(len(vectors)):\n",
    "        temp = []\n",
    "        for j in range(len(vectors)):\n",
    "            temp.append(distance.cosine(vectors[i], vectors[j]))\n",
    "        distances.append(temp)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cosine_similarity\n",
      "[0.0, 0.3291796067500631, 0.6666666666666667]\n",
      "[0.3291796067500631, 0.0, 0.7018576030000281]\n",
      "[0.6666666666666667, 0.7018576030000281, 0.0]\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(vectors)\n",
    "print('# cosine_similarity')\n",
    "for index in range(len(similarities)):\n",
    "    print(similarities[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fileのpathを配列に格納する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Data_NL=[]\n",
    "for i in range(1,14):\n",
    "    List_Data_NL = glob.glob( \"./data/*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in List_Data_NL:\n",
    "    with open(l) as f:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!-- saved from url=(0035)https://www.nltk.org/book/ch02.html -->\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><script language=\"javascript\" type=\"text/javascript\">\n",
      "\n",
      "function astext(node)\n",
      "{\n",
      "    return node.innerHTML.replace(/(<([^>]+)>)/ig,\"\")\n",
      "                         .replace(/&gt;/ig, \">\")\n",
      "                         .replace(/&lt;/ig, \"<\")\n",
      "                         .replace(/&quot;/ig, '\"')\n",
      "                         .replace(/&amp;/ig, \"&\");\n",
      "}\n",
      "\n",
      "function copy_notify(node, bar_color, data)\n",
      "{\n",
      "    // The outer box: relative + inline positioning.\n",
      "    var box1 = document.createElement(\"div\");\n",
      "    box1.style.position = \"relative\";\n",
      "    box1.style.display = \"inline\";\n",
      "    box1.style.top = \"2em\";\n",
      "    box1.style.left = \"1em\";\n",
      "  \n",
      "    // A shadow for fun\n",
      "    var shadow = document.createElement(\"div\");\n",
      "    shadow.style.position = \"absolute\";\n",
      "    shadow.style.left = \"-1.3em\";\n",
      "    shadow.style.top = \"-1.3em\";\n",
      "    shadow.style.background = \"#404040\";\n",
      "    \n",
      "    // The inner box: absolute positioning.\n",
      "    var box2 = document.createElement(\"div\");\n",
      "    box2.style.position = \"relative\";\n",
      "    box2.style.border = \"1px solid #a0a0a0\";\n",
      "    box2.style.left = \"-.2em\";\n",
      "    box2.style.top = \"-.2em\";\n",
      "    box2.style.background = \"white\";\n",
      "    box2.style.padding = \".3em .4em .3em .4em\";\n",
      "    box2.style.fontStyle = \"normal\";\n",
      "    box2.style.background = \"#f0e0e0\";\n",
      "\n",
      "    node.insertBefore(box1, node.childNodes.item(0));\n",
      "    box1.appendChild(shadow);\n",
      "    shadow.appendChild(box2);\n",
      "    box2.innerHTML=\"Copied&nbsp;to&nbsp;the&nbsp;clipboard: \" +\n",
      "                   \"<pre class='copy-notify'>\"+\n",
      "                   data+\"</pre>\";\n",
      "    setTimeout(function() { node.removeChild(box1); }, 1000);\n",
      "\n",
      "    var elt = node.parentNode.firstChild;\n",
      "    elt.style.background = \"#ffc0c0\";\n",
      "    setTimeout(function() { elt.style.background = bar_color; }, 200);\n",
      "}\n",
      "\n",
      "function copy_codeblock_to_clipboard(node)\n",
      "{\n",
      "    var data = astext(node)+\"\\n\";\n",
      "    if (copy_text_to_clipboard(data)) {\n",
      "        copy_notify(node, \"#40a060\", data);\n",
      "    }\n",
      "}\n",
      "\n",
      "function copy_doctest_to_clipboard(node)\n",
      "{\n",
      "    var s = astext(node)+\"\\n   \";\n",
      "    var data = \"\";\n",
      "\n",
      "    var start = 0;\n",
      "    var end = s.indexOf(\"\\n\");\n",
      "    while (end >= 0) {\n",
      "        if (s.substring(start, start+4) == \">>> \") {\n",
      "            data += s.substring(start+4, end+1);\n",
      "        }\n",
      "        else if (s.substring(start, start+4) == \"... \") {\n",
      "            data += s.substring(start+4, end+1);\n",
      "        }\n",
      "        /*\n",
      "        else if (end-start > 1) {\n",
      "            data += \"# \" + s.substring(start, end+1);\n",
      "        }*/\n",
      "        // Grab the next line.\n",
      "        start = end+1;\n",
      "        end = s.indexOf(\"\\n\", start);\n",
      "    }\n",
      "    \n",
      "    if (copy_text_to_clipboard(data)) {\n",
      "        copy_notify(node, \"#4060a0\", data);\n",
      "    }\n",
      "}\n",
      "    \n",
      "function copy_text_to_clipboard(data)\n",
      "{\n",
      "    if (window.clipboardData) {\n",
      "        window.clipboardData.setData(\"Text\", data);\n",
      "        return true;\n",
      "     }\n",
      "    else if (window.netscape) {\n",
      "        // w/ default firefox settings, permission will be denied for this:\n",
      "        netscape.security.PrivilegeManager\n",
      "                      .enablePrivilege(\"UniversalXPConnect\");\n",
      "    \n",
      "        var clip = Components.classes[\"@mozilla.org/widget/clipboard;1\"]\n",
      "                      .createInstance(Components.interfaces.nsIClipboard);\n",
      "        if (!clip) return;\n",
      "    \n",
      "        var trans = Components.classes[\"@mozilla.org/widget/transferable;1\"]\n",
      "                       .createInstance(Components.interfaces.nsITransferable);\n",
      "        if (!trans) return;\n",
      "    \n",
      "        trans.addDataFlavor(\"text/unicode\");\n",
      "    \n",
      "        var str = new Object();\n",
      "        var len = new Object();\n",
      "    \n",
      "        var str = Components.classes[\"@mozilla.org/supports-string;1\"]\n",
      "                     .createInstance(Components.interfaces.nsISupportsString);\n",
      "        var datacopy=data;\n",
      "        str.data=datacopy;\n",
      "        trans.setTransferData(\"text/unicode\",str,datacopy.length*2);\n",
      "        var clipid=Components.interfaces.nsIClipboard;\n",
      "    \n",
      "        if (!clip) return false;\n",
      "    \n",
      "        clip.setData(trans,null,clipid.kGlobalClipboard);\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\n",
      "//-->\n",
      "</script>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<meta name=\"generator\" content=\"Docutils 0.15: http://docutils.sourceforge.net/\">\n",
      "<title>2. Accessing Text Corpora and Lexical Resources</title>\n",
      "<style type=\"text/css\">\n",
      "\n",
      "/*\n",
      ":Author: Edward Loper, James Curran\n",
      ":Copyright: This stylesheet has been placed in the public domain.\n",
      "\n",
      "Stylesheet for use with Docutils.\n",
      "\n",
      "This stylesheet defines new css classes used by NLTK.\n",
      "\n",
      "It uses a Python syntax highlighting scheme that matches\n",
      "the colour scheme used by IDLE, which makes it easier for\n",
      "beginners to check they are typing things in correctly.\n",
      "*/\n",
      "\n",
      "/* Include the standard docutils stylesheet. */\n",
      "@import url(default.css);\n",
      "\n",
      "/* Custom inline roles */\n",
      "span.placeholder    { font-style: italic; font-family: monospace; }\n",
      "span.example        { font-style: italic; }\n",
      "span.emphasis       { font-style: italic; }\n",
      "span.termdef        { font-weight: bold; }\n",
      "/*span.term           { font-style: italic; }*/\n",
      "span.category       { font-variant: small-caps; }\n",
      "span.feature        { font-variant: small-caps; }\n",
      "span.fval           { font-style: italic; }\n",
      "span.math           { font-style: italic; }\n",
      "span.mathit         { font-style: italic; }\n",
      "span.lex            { font-variant: small-caps; }\n",
      "span.guide-linecount{ text-align: right; display: block;}\n",
      "\n",
      "/* Python souce code listings */\n",
      "span.pysrc-prompt   { color: #9b0000; }\n",
      "span.pysrc-more     { color: #9b00ff; }\n",
      "span.pysrc-keyword  { color: #e06000; }\n",
      "span.pysrc-builtin  { color: #940094; }\n",
      "span.pysrc-string   { color: #00aa00; }\n",
      "span.pysrc-comment  { color: #ff0000; }\n",
      "span.pysrc-output   { color: #0000ff; }\n",
      "span.pysrc-except   { color: #ff0000; }\n",
      "span.pysrc-defname  { color: #008080; }\n",
      "\n",
      "\n",
      "/* Doctest blocks */\n",
      "pre.doctest         { margin: 0; padding: 0; font-weight: bold; }\n",
      "div.doctest         { margin: 0 1em 1em 1em; padding: 0; }\n",
      "table.doctest       { margin: 0; padding: 0;\n",
      "                      border-top: 1px solid gray;\n",
      "                      border-bottom: 1px solid gray; }\n",
      "pre.copy-notify     { margin: 0; padding: 0.2em; font-weight: bold;\n",
      "                      background-color: #ffffff; }\n",
      "\n",
      "/* Python source listings */\n",
      "div.pylisting       { margin: 0 1em 1em 1em; padding: 0; }\n",
      "table.pylisting     { margin: 0; padding: 0;\n",
      "                      border-top: 1px solid gray; }\n",
      "td.caption { border-top: 1px solid black; margin: 0; padding: 0; }\n",
      ".caption-label { font-weight: bold;  }\n",
      "td.caption p { margin: 0; padding: 0; font-style: normal;}\n",
      "\n",
      "table tr td.codeblock { \n",
      "  padding: 0.2em ! important; margin: 0;\n",
      "  border-left: 1px solid gray;\n",
      "  border-right: 2px solid gray;\n",
      "  border-top: 0px solid gray;\n",
      "  border-bottom: 1px solid gray;\n",
      "  font-weight: bold; background-color: #eeffee;\n",
      "}\n",
      "table pre span {\n",
      "  white-space: pre-wrap;\n",
      "}\n",
      "table tr td.doctest  { \n",
      "  padding: 0.2em; margin: 0;\n",
      "  border-left: 1px solid gray;\n",
      "  border-right: 2px solid gray;\n",
      "  border-top: 0px solid gray;\n",
      "  border-bottom: 1px solid gray;\n",
      "  font-weight: bold; background-color: #eeeeff;\n",
      "}\n",
      "\n",
      "td.codeblock table tr td.copybar {\n",
      "    background: #40a060; border: 1px solid gray;\n",
      "    font-family: monospace; padding: 0; margin: 0; }\n",
      "td.doctest table tr td.copybar {\n",
      "    background: #4060a0; border: 1px solid gray;\n",
      "    font-family: monospace; padding: 0; margin: 0; }\n",
      "\n",
      "td.pysrc { padding-left: 0.5em; }\n",
      "\n",
      "img.callout { border-width: 0px; }\n",
      "\n",
      "table.docutils {\n",
      "    border-style: solid;\n",
      "    border-width: 1px;\n",
      "    margin-top: 6px;\n",
      "    border-color: grey;\n",
      "    border-collapse: collapse; }\n",
      "\n",
      "table.docutils th {\n",
      "    border-style: none;\n",
      "    border-width: 1px;\n",
      "    border-color: grey;\n",
      "    padding: 0 .5em 0 .5em; }\n",
      "\n",
      "table.docutils td {\n",
      "    border-style: none;\n",
      "    border-width: 1px;\n",
      "    border-color: grey; \n",
      "    padding: 0 .5em 0 .5em; }\n",
      "\n",
      "table.footnote td { padding: 0; }\n",
      "table.footnote { border-width: 0; }\n",
      "table.footnote td { border-width: 0; }\n",
      "table.footnote th { border-width: 0; }\n",
      "\n",
      "table.noborder { border-width: 0; }\n",
      "\n",
      "table.example pre { margin-top: 4px; margin-bottom: 0; }\n",
      "\n",
      "/* For figures & tables */\n",
      "p.caption { margin-bottom: 0; }\n",
      "div.figure { text-align: center; }\n",
      "\n",
      "/* The index */\n",
      "div.index { border: 1px solid black;\n",
      "            background-color: #eeeeee; }\n",
      "div.index h1 { padding-left: 0.5em; margin-top: 0.5ex;\n",
      "               border-bottom: 1px solid black; }\n",
      "ul.index { margin-left: 0.5em; padding-left: 0; }\n",
      "li.index { list-style-type: none; }\n",
      "p.index-heading { font-size: 120%; font-style: italic; margin: 0; }\n",
      "li.index ul { margin-left: 2em; padding-left: 0; }\n",
      "\n",
      "/* 'Note' callouts */\n",
      "div.note\n",
      "{\n",
      "  border-right:   #87ceeb 1px solid;\n",
      "  padding-right: 4px;\n",
      "  border-top: #87ceeb 1px solid;\n",
      "  padding-left: 4px;\n",
      "  padding-bottom: 4px;\n",
      "  margin: 2px 5% 10px;\n",
      "  border-left: #87ceeb 1px solid;\n",
      "  padding-top: 4px;\n",
      "  border-bottom: #87ceeb 1px solid;\n",
      "  font-style: normal;\n",
      "  font-family: verdana, arial;\n",
      "  background-color: #b0c4de;\n",
      "}\n",
      "\n",
      "table.avm { border: 0px solid black; width: 0; }\n",
      "table.avm tbody tr {border: 0px solid black; }\n",
      "table.avm tbody tr td { padding: 2px; }\n",
      "table.avm tbody tr td.avm-key { padding: 5px; font-variant: small-caps; }\n",
      "table.avm tbody tr td.avm-eq { padding: 5px; }\n",
      "table.avm tbody tr td.avm-val { padding: 5px; font-style: italic; }\n",
      "p.avm-empty { font-style: normal; }\n",
      "table.avm colgroup col { border: 0px solid black; }\n",
      "table.avm tbody tr td.avm-topleft \n",
      "    { border-left: 2px solid #000080; border-top: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-botleft \n",
      "    { border-left: 2px solid #000080; border-bottom: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-topright\n",
      "    { border-right: 2px solid #000080; border-top: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-botright\n",
      "    { border-right: 2px solid #000080; border-bottom: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-left\n",
      "    { border-left: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-right\n",
      "    { border-right: 2px solid #000080; }\n",
      "table.avm tbody tr td.avm-topbotleft\n",
      "    { border: 2px solid #000080; border-right: 0px solid black; }\n",
      "table.avm tbody tr td.avm-topbotright\n",
      "    { border: 2px solid #000080; border-left: 0px solid black; }\n",
      "table.avm tbody tr td.avm-ident\n",
      "    { font-size: 80%; padding: 0; padding-left: 2px; vertical-align: top; }\n",
      ".avm-pointer\n",
      "{ border: 1px solid #008000; padding: 1px; color: #008000; \n",
      "  background: #c0ffc0; font-style: normal; }\n",
      "\n",
      "table.gloss { border: 0px solid black; width: 0; }\n",
      "table.gloss tbody tr { border: 0px solid black; }\n",
      "table.gloss tbody tr td { border: 0px solid black; }\n",
      "table.gloss colgroup col { border: 0px solid black; }\n",
      "table.gloss p { margin: 0; padding: 0; }\n",
      "\n",
      "table.rst-example { border: 1px solid black; }\n",
      "table.rst-example tbody tr td { background: #eeeeee; }\n",
      "table.rst-example thead tr th { background: #c0ffff; }\n",
      "td.rst-raw { width: 0; }\n",
      "\n",
      "/* Used by nltk.org/doc/test: */\n",
      "div.doctest-list { text-align: center; }\n",
      "table.doctest-list { border: 1px solid black;\n",
      "  margin-left: auto; margin-right: auto;\n",
      "}\n",
      "table.doctest-list tbody tr td { background: #eeeeee;\n",
      "  border: 1px solid #cccccc; text-align: left; }\n",
      "table.doctest-list thead tr th { background: #304050; color: #ffffff;\n",
      "  border: 1px solid #000000;}\n",
      "table.doctest-list thead tr a { color: #ffffff; }\n",
      "span.doctest-passed { color: #008000; }\n",
      "span.doctest-failed { color: #800000; }\n",
      "\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"document\" id=\"accessing-text-corpora-and-lexical-resources\">\n",
      "<span id=\"chap-corpora\"></span>\n",
      "<h1 class=\"title\">2. Accessing Text Corpora and Lexical Resources</h1>\n",
      "\n",
      "<!-- -*- mode: rst -*- -->\n",
      "<!-- -*- mode: rst -*- -->\n",
      "<!-- CAP abbreviations (map to small caps in LaTeX) -->\n",
      "<!-- Other candidates for global consistency -->\n",
      "<!-- PTB removed since it must be indexed -->\n",
      "<!-- WN removed since it must be indexed -->\n",
      "<!-- misc & punctuation -->\n",
      "<!-- cdots was unicode U+22EF but not working -->\n",
      "<!-- exercise meta-tags -->\n",
      "<!-- Unicode tests -->\n",
      "<!-- phonetic -->\n",
      "<!-- misc -->\n",
      "<!-- used in Unicode section -->\n",
      "<!-- arrows -->\n",
      "<!-- unification stuff -->\n",
      "<!-- Math & Logic -->\n",
      "<!-- sets -->\n",
      "<!-- Greek -->\n",
      "<!-- Chinese -->\n",
      "<!-- URLs -->\n",
      "<!-- Python example - a snippet of code in running text -->\n",
      "<!-- PlaceHolder example -  something that should be replaced by actual code -->\n",
      "<!-- Linguistic eXample - cited form in running text -->\n",
      "<!-- Emphasized (more declarative than just using *) -->\n",
      "<!-- Grammatical Category - e.g. NP and verb as technical terms\n",
      ".. role:: gc\n",
      "   :class: category -->\n",
      "<!-- Math expression - e.g. especially for variables -->\n",
      "<!-- Textual Math expression - for words 'inside' a math environment -->\n",
      "<!-- Feature (or attribute) -->\n",
      "<!-- Raw LaTeX -->\n",
      "<!-- Raw HTML -->\n",
      "<!-- Feature-value -->\n",
      "<!-- Lexemes -->\n",
      "<!-- Replacements that rely on previous definitions :-) -->\n",
      "<!-- TODO: add Mark Twain -->\n",
      "<!-- TODO: discussion of resource rich/poor languages in section on corpora in other languages\n",
      "number of languages in the world, Ethnologue, etc -->\n",
      "<!-- TODO: explain double vs single vs triple quotes for strings -->\n",
      "<!-- TODO: extracting dates from a tokenized text -->\n",
      "<!-- TODO: finding a sequence of words matching some pattern (including doubled words, e.g. \"the thing is is that\") -->\n",
      "<!-- TODO: The Lexicon:\n",
      "* words are more than just the output of tokenization\n",
      "* explore what it means for a document to contain a word\n",
      "* ways this can fail: mis-spelling; different endings; synonyms; homonyms\n",
      "* type vs token distinction; connection of types to lemmas (cf issue 201)\n",
      "* concept of \"word\", many-to-many mapping between forms and meanings\n",
      "* why the lexicon is an open set, lexical productivity and challenge for NLP\n",
      "* morphology -->\n",
      "<!-- Exploratory data analysis, a technique for learning about a specific\n",
      "linguistic pattern, consists of four steps: search, categorization,\n",
      "counting, and hypothesis refinement. -->\n",
      "<!-- TODO: expand the summary -->\n",
      "<!-- TODO: explain reload() in connection with redefining the lexical_diversity function\n",
      "(suggested in issue 170) -->\n",
      "<!-- TODO: style - - reduce number of sents starting with \"We can\"? -->\n",
      "<p>Practical work in Natural Language Processing typically uses\n",
      "large bodies of linguistic data, or <a name=\"corpora_index_term\"><span class=\"termdef\">corpora</span>.\n",
      "The goal of this chapter is to answer the following questions:</a></p><a name=\"corpora_index_term\">\n",
      "<ol class=\"arabic simple\">\n",
      "<li>What are some useful text corpora and lexical resources, and how can we access them with Python?</li>\n",
      "<li>Which Python constructs are most helpful for this work?</li>\n",
      "<li>How do we avoid repeating ourselves when writing Python code?</li>\n",
      "</ol>\n",
      "<p>This chapter continues to present programming concepts by example, in the\n",
      "context of a linguistic processing task.  We will wait until later before\n",
      "exploring each Python construct systematically.  Don't worry if you see\n",
      "an example that contains something unfamiliar; simply try it out and see\n",
      "what it does, and — if you're game — modify it by substituting\n",
      "some part of the code with a different text or word.  This way you will\n",
      "associate a task with a programming idiom, and learn the hows and whys later.</p>\n",
      "</a><div class=\"section\" id=\"accessing-text-corpora\"><a name=\"corpora_index_term\">\n",
      "<span id=\"sec-extracting-text-from-corpora\"></span><h1>1&nbsp;&nbsp;&nbsp;Accessing Text Corpora</h1>\n",
      "</a><p><a name=\"corpora_index_term\">As just mentioned, a text corpus is a large body of text. Many\n",
      "corpora are designed to contain a careful balance of material\n",
      "in one or more genres.  We examined some small text collections in\n",
      "</a><a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#chap-introduction\">1.</a>, such as the speeches known as the US Presidential\n",
      "Inaugural Addresses.  This particular corpus actually contains dozens\n",
      "of individual texts — one per address — but for convenience\n",
      "we glued them end-to-end and treated them as a single text.\n",
      "<a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#chap-introduction\">1.</a> also used various pre-defined texts that\n",
      "we accessed by typing <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">from</span> nltk.book <span class=\"pysrc-keyword\">import</span> *</span></tt>.  However, since we want\n",
      "to be able to work with other texts, this section examines a\n",
      "variety of text corpora. We'll see how\n",
      "to select individual texts, and how to work with them.</p>\n",
      "<div class=\"section\" id=\"gutenberg-corpus\">\n",
      "<h2>1.1&nbsp;&nbsp;&nbsp;Gutenberg Corpus</h2>\n",
      "<p>NLTK includes a small selection of texts from the Project Gutenberg\n",
      "electronic text archive, which contains\n",
      "some 25,000 free electronic books, hosted at <tt class=\"doctest\"><span class=\"pre\">http://www.gutenberg.org/</span></tt>.  We begin\n",
      "by getting the Python interpreter to load the NLTK package,\n",
      "then ask to see <tt class=\"doctest\"><span class=\"pre\">nltk.corpus.gutenberg.fileids()</span></tt>, the file identifiers in\n",
      "this corpus:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">import</span> nltk\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.gutenberg.fileids()\n",
      "<span class=\"pysrc-output\">['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt',</span>\n",
      "<span class=\"pysrc-output\">'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt',</span>\n",
      "<span class=\"pysrc-output\">'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt',</span>\n",
      "<span class=\"pysrc-output\">'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt',</span>\n",
      "<span class=\"pysrc-output\">'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt',</span>\n",
      "<span class=\"pysrc-output\">'shakespeare-macbeth.txt', 'whitman-leaves.txt']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Let's pick out the first of these texts — <em>Emma</em> by Jane Austen — and\n",
      "give it a short name, <tt class=\"doctest\"><span class=\"pre\">emma</span></tt>, then find out how many words it contains:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>emma = nltk.corpus.gutenberg.words(<span class=\"pysrc-string\">'austen-emma.txt'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>len(emma)\n",
      "<span class=\"pysrc-output\">192427</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p>In <a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>, we showed how you\n",
      "could carry out concordancing of a text such as <tt class=\"doctest\"><span class=\"pre\">text1</span></tt> with the\n",
      "command <tt class=\"doctest\"><span class=\"pre\">text1.concordance()</span></tt>. However, this assumes that you are\n",
      "using one of the nine texts obtained as a result of doing <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">from</span>\n",
      "nltk.book <span class=\"pysrc-keyword\">import</span> *</span></tt>. Now that you have started examining data from\n",
      "<tt class=\"doctest\"><span class=\"pre\">nltk.corpus</span></tt>, as in the previous example, you have to employ the\n",
      "following pair of statements to perform concordancing and other\n",
      "tasks from <a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>emma = nltk.Text(nltk.corpus.gutenberg.words(<span class=\"pysrc-string\">'austen-emma.txt'</span>))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>emma.concordance(<span class=\"pysrc-string\">\"surprize\"</span>)</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<p>When we defined <tt class=\"doctest\"><span class=\"pre\">emma</span></tt>, we invoked the <tt class=\"doctest\"><span class=\"pre\">words()</span></tt> function of the <tt class=\"doctest\"><span class=\"pre\">gutenberg</span></tt>\n",
      "object in NLTK's <tt class=\"doctest\"><span class=\"pre\">corpus</span></tt> package.\n",
      "But since it is cumbersome to type such long names all the time, Python provides\n",
      "another version of the <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span></span></tt> statement, as follows:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> gutenberg\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>gutenberg.fileids()\n",
      "<span class=\"pysrc-output\">['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>emma = gutenberg.words(<span class=\"pysrc-string\">'austen-emma.txt'</span>)</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Let's write a short program to display other information about each\n",
      "text, by looping over all the values of <tt class=\"doctest\"><span class=\"pre\">fileid</span></tt> corresponding to\n",
      "the <tt class=\"doctest\"><span class=\"pre\">gutenberg</span></tt> file identifiers listed earlier and then computing\n",
      "statistics for each text.  For a compact output display, we will round\n",
      "each number to the nearest integer, using <tt class=\"doctest\"><span class=\"pre\">round()</span></tt>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> gutenberg.fileids():\n",
      "<span class=\"pysrc-more\">... </span>    num_chars = len(gutenberg.raw(fileid)) <a name=\"raw-access\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-raw-access\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>    num_words = len(gutenberg.words(fileid))\n",
      "<span class=\"pysrc-more\">... </span>    num_sents = len(gutenberg.sents(fileid))\n",
      "<span class=\"pysrc-more\">... </span>    num_vocab = len(set(w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> gutenberg.words(fileid)))\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">5 25 26 austen-emma.txt</span>\n",
      "<span class=\"pysrc-output\">5 26 17 austen-persuasion.txt</span>\n",
      "<span class=\"pysrc-output\">5 28 22 austen-sense.txt</span>\n",
      "<span class=\"pysrc-output\">4 34 79 bible-kjv.txt</span>\n",
      "<span class=\"pysrc-output\">5 19 5 blake-poems.txt</span>\n",
      "<span class=\"pysrc-output\">4 19 14 bryant-stories.txt</span>\n",
      "<span class=\"pysrc-output\">4 18 12 burgess-busterbrown.txt</span>\n",
      "<span class=\"pysrc-output\">4 20 13 carroll-alice.txt</span>\n",
      "<span class=\"pysrc-output\">5 20 12 chesterton-ball.txt</span>\n",
      "<span class=\"pysrc-output\">5 23 11 chesterton-brown.txt</span>\n",
      "<span class=\"pysrc-output\">5 18 11 chesterton-thursday.txt</span>\n",
      "<span class=\"pysrc-output\">4 21 25 edgeworth-parents.txt</span>\n",
      "<span class=\"pysrc-output\">5 26 15 melville-moby_dick.txt</span>\n",
      "<span class=\"pysrc-output\">5 52 11 milton-paradise.txt</span>\n",
      "<span class=\"pysrc-output\">4 12 9 shakespeare-caesar.txt</span>\n",
      "<span class=\"pysrc-output\">4 12 8 shakespeare-hamlet.txt</span>\n",
      "<span class=\"pysrc-output\">4 12 7 shakespeare-macbeth.txt</span>\n",
      "<span class=\"pysrc-output\">5 36 12 whitman-leaves.txt</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>This program displays three statistics for each text:\n",
      "average word length, average sentence length, and the number of times each vocabulary\n",
      "item appears in the text on average (our lexical diversity score).\n",
      "Observe that average word length appears to be a general property of English, since\n",
      "it has a recurrent value of <tt class=\"doctest\"><span class=\"pre\">4</span></tt>.  (In fact, the average word length is really\n",
      "<tt class=\"doctest\"><span class=\"pre\">3</span></tt> not <tt class=\"doctest\"><span class=\"pre\">4</span></tt>, since the <tt class=\"doctest\"><span class=\"pre\">num_chars</span></tt> variable counts space characters.)\n",
      "By contrast average sentence length and lexical diversity\n",
      "appear to be characteristics of particular authors.</p>\n",
      "<p>The previous example also showed how we can access the \"raw\" text of the book <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#raw-access\"><span id=\"ref-raw-access\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>,\n",
      "not split up into tokens.  The <tt class=\"doctest\"><span class=\"pre\">raw()</span></tt> function gives us the contents of the file\n",
      "without any linguistic processing.  So, for example, <tt class=\"doctest\"><span class=\"pre\">len(gutenberg.raw(<span class=\"pysrc-string\">'blake-poems.txt'</span>))</span></tt>\n",
      "tells us how many <em>letters</em> occur in the text, including the spaces between words.\n",
      "The <tt class=\"doctest\"><span class=\"pre\">sents()</span></tt> function divides the text up into its sentences, where each sentence is\n",
      "a list of words:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>macbeth_sentences = gutenberg.sents(<span class=\"pysrc-string\">'shakespeare-macbeth.txt'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>macbeth_sentences\n",
      "<span class=\"pysrc-output\">[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare',</span>\n",
      "<span class=\"pysrc-output\">'1603', ']'], ['Actus', 'Primus', '.'], ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>macbeth_sentences[1116]\n",
      "<span class=\"pysrc-output\">['Double', ',', 'double', ',', 'toile', 'and', 'trouble', ';',</span>\n",
      "<span class=\"pysrc-output\">'Fire', 'burne', ',', 'and', 'Cauldron', 'bubble']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>longest_len = max(len(s) <span class=\"pysrc-keyword\">for</span> s <span class=\"pysrc-keyword\">in</span> macbeth_sentences)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[s <span class=\"pysrc-keyword\">for</span> s <span class=\"pysrc-keyword\">in</span> macbeth_sentences <span class=\"pysrc-keyword\">if</span> len(s) == longest_len]\n",
      "<span class=\"pysrc-output\">[['Doubtfull', 'it', 'stood', ',', 'As', 'two', 'spent', 'Swimmers', ',', 'that',</span>\n",
      "<span class=\"pysrc-output\">'doe', 'cling', 'together', ',', 'And', 'choake', 'their', 'Art', ':', 'The',</span>\n",
      "<span class=\"pysrc-output\">'mercilesse', 'Macdonwald', ...]]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\">Most NLTK corpus readers include a variety of access methods\n",
      "apart from <tt class=\"doctest\"><span class=\"pre\">words()</span></tt>, <tt class=\"doctest\"><span class=\"pre\">raw()</span></tt>, and <tt class=\"doctest\"><span class=\"pre\">sents()</span></tt>.  Richer\n",
      "linguistic content is available from some corpora, such as part-of-speech\n",
      "tags, dialogue tags, syntactic trees, and so forth; we will see these\n",
      "in later chapters.</p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"web-and-chat-text\">\n",
      "<h2>1.2&nbsp;&nbsp;&nbsp;Web and Chat Text</h2>\n",
      "<p>Although Project Gutenberg contains thousands of books, it represents established\n",
      "literature.  It is important to consider less formal language as well.  NLTK's\n",
      "small collection of web text includes content from a Firefox discussion forum,\n",
      "conversations overheard in New York, the movie script of <em>Pirates of the Carribean</em>,\n",
      "personal advertisements, and wine reviews:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> webtext\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> webtext.fileids():\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(fileid, webtext.raw(fileid)[:65], <span class=\"pysrc-string\">'...'</span>)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se...</span>\n",
      "<span class=\"pysrc-output\">grail.txt SCENE 1: [wind] [clop clop clop] KING ARTHUR: Whoa there!  [clop...</span>\n",
      "<span class=\"pysrc-output\">overheard.txt White guy: So, do you have any plans for this evening? Asian girl...</span>\n",
      "<span class=\"pysrc-output\">pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott &amp; Terr...</span>\n",
      "<span class=\"pysrc-output\">singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun...</span>\n",
      "<span class=\"pysrc-output\">wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb...</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>There is also a corpus of instant messaging chat sessions, originally collected\n",
      "by the Naval Postgraduate School for research on automatic detection of Internet predators.\n",
      "The corpus contains over 10,000 posts, anonymized by replacing usernames with generic\n",
      "names of the form \"UserNNN\", and manually edited to remove any other identifying information.\n",
      "The corpus is organized into 15 files, where each file contains several hundred posts\n",
      "collected on a given date, for an age-specific chatroom (teens, 20s, 30s, 40s, plus a\n",
      "generic adults chatroom).  The filename contains the date, chatroom,\n",
      "and number of posts; e.g., <tt class=\"doctest\"><span class=\"pre\">10-19-20s_706posts.xml</span></tt> contains 706 posts gathered from\n",
      "the 20s chat room on 10/19/2006.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> nps_chat\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>chatroom = nps_chat.posts(<span class=\"pysrc-string\">'10-19-20s_706posts.xml'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>chatroom[123]\n",
      "<span class=\"pysrc-output\">['i', 'do', \"n't\", 'want', 'hot', 'pics', 'of', 'a', 'female', ',',</span>\n",
      "<span class=\"pysrc-output\">'I', 'can', 'look', 'in', 'a', 'mirror', '.']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"brown-corpus\">\n",
      "<h2>1.3&nbsp;&nbsp;&nbsp;Brown Corpus</h2>\n",
      "<p>The Brown Corpus was the first million-word electronic\n",
      "corpus of English, created in 1961 at Brown University.\n",
      "This corpus contains text from 500 sources, and the sources\n",
      "have been categorized by genre, such as <em>news</em>, <em>editorial</em>, and so on.\n",
      "<a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#tab-brown-sources\">1.1</a> gives an example of each genre\n",
      "(for a complete list, see <tt class=\"doctest\"><span class=\"pre\">http://icame.uib.no/brown/bcm-los.html</span></tt>).</p>\n",
      "<span class=\"target\" id=\"tab-brown-sources\"></span><p class=\"caption\"><span class=\"caption-label\">Table 1.1</span>: </p><p>Example Document for Each Section of the Brown Corpus</p><p></p><table border=\"1\" class=\"docutils\" id=\"tab-brown-sources\">\n",
      "<colgroup>\n",
      "<col width=\"3%\">\n",
      "<col width=\"8%\">\n",
      "<col width=\"15%\">\n",
      "<col width=\"74%\">\n",
      "</colgroup>\n",
      "<thead valign=\"bottom\">\n",
      "<tr><th class=\"head\">ID</th>\n",
      "<th class=\"head\">File</th>\n",
      "<th class=\"head\">Genre</th>\n",
      "<th class=\"head\">Description</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<tr><td>A16</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">ca16</span></tt></td>\n",
      "<td>news</td>\n",
      "<td>Chicago Tribune: <em>Society Reportage</em></td>\n",
      "</tr>\n",
      "<tr><td>B02</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cb02</span></tt></td>\n",
      "<td>editorial</td>\n",
      "<td>Christian Science Monitor: <em>Editorials</em></td>\n",
      "</tr>\n",
      "<tr><td>C17</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cc17</span></tt></td>\n",
      "<td>reviews</td>\n",
      "<td>Time Magazine: <em>Reviews</em></td>\n",
      "</tr>\n",
      "<tr><td>D12</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cd12</span></tt></td>\n",
      "<td>religion</td>\n",
      "<td>Underwood: <em>Probing the Ethics of Realtors</em></td>\n",
      "</tr>\n",
      "<tr><td>E36</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">ce36</span></tt></td>\n",
      "<td>hobbies</td>\n",
      "<td>Norling: <em>Renting a Car in Europe</em></td>\n",
      "</tr>\n",
      "<tr><td>F25</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cf25</span></tt></td>\n",
      "<td>lore</td>\n",
      "<td>Boroff: <em>Jewish Teenage Culture</em></td>\n",
      "</tr>\n",
      "<tr><td>G22</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cg22</span></tt></td>\n",
      "<td>belles_lettres</td>\n",
      "<td>Reiner: <em>Coping with Runaway Technology</em></td>\n",
      "</tr>\n",
      "<tr><td>H15</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">ch15</span></tt></td>\n",
      "<td>government</td>\n",
      "<td>US Office of Civil and Defence Mobilization: <em>The Family Fallout Shelter</em></td>\n",
      "</tr>\n",
      "<tr><td>J17</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cj19</span></tt></td>\n",
      "<td>learned</td>\n",
      "<td>Mosteller: <em>Probability with Statistical Applications</em></td>\n",
      "</tr>\n",
      "<tr><td>K04</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">ck04</span></tt></td>\n",
      "<td>fiction</td>\n",
      "<td>W.E.B. Du Bois: <em>Worlds of Color</em></td>\n",
      "</tr>\n",
      "<tr><td>L13</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cl13</span></tt></td>\n",
      "<td>mystery</td>\n",
      "<td>Hitchens: <em>Footsteps in the Night</em></td>\n",
      "</tr>\n",
      "<tr><td>M01</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cm01</span></tt></td>\n",
      "<td>science_fiction</td>\n",
      "<td>Heinlein: <em>Stranger in a Strange Land</em></td>\n",
      "</tr>\n",
      "<tr><td>N14</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cn15</span></tt></td>\n",
      "<td>adventure</td>\n",
      "<td>Field: <em>Rattlesnake Ridge</em></td>\n",
      "</tr>\n",
      "<tr><td>P12</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cp12</span></tt></td>\n",
      "<td>romance</td>\n",
      "<td>Callaghan: <em>A Passion in Rome</em></td>\n",
      "</tr>\n",
      "<tr><td>R06</td>\n",
      "<td><tt class=\"doctest\"><span class=\"pre\">cr06</span></tt></td>\n",
      "<td>humor</td>\n",
      "<td>Thurber: <em>The Future, If Any, of Comedy</em></td>\n",
      "</tr>\n",
      "</tbody>\n",
      "\n",
      "\n",
      "</table>\n",
      "<p>We can access the corpus as a list of words, or a list of sentences (where each sentence\n",
      "is itself just a list of words).  We can optionally specify particular categories or files to read:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> brown\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>brown.categories()\n",
      "<span class=\"pysrc-output\">['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies',</span>\n",
      "<span class=\"pysrc-output\">'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance',</span>\n",
      "<span class=\"pysrc-output\">'science_fiction']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>brown.words(categories=<span class=\"pysrc-string\">'news'</span>)\n",
      "<span class=\"pysrc-output\">['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>brown.words(fileids=[<span class=\"pysrc-string\">'cg22'</span>])\n",
      "<span class=\"pysrc-output\">['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>brown.sents(categories=[<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'editorial'</span>, <span class=\"pysrc-string\">'reviews'</span>])\n",
      "<span class=\"pysrc-output\">[['The', 'Fulton', 'County'...], ['The', 'jury', 'further'...], ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The Brown Corpus is a convenient resource for studying systematic differences between\n",
      "genres, a kind of linguistic inquiry known as <a name=\"stylistics_index_term\"><span class=\"termdef\">stylistics</span>.\n",
      "Let's compare genres in their usage of modal verbs.  The first step\n",
      "is to produce the counts for a particular genre.  Remember to\n",
      "<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span> nltk</span></tt> before doing the following:</a></p><a name=\"stylistics_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> brown\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>news_text = brown.words(categories=<span class=\"pysrc-string\">'news'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>fdist = nltk.FreqDist(w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> news_text)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>modals = [<span class=\"pysrc-string\">'can'</span>, <span class=\"pysrc-string\">'could'</span>, <span class=\"pysrc-string\">'may'</span>, <span class=\"pysrc-string\">'might'</span>, <span class=\"pysrc-string\">'must'</span>, <span class=\"pysrc-string\">'will'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> m <span class=\"pysrc-keyword\">in</span> modals:\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(m + <span class=\"pysrc-string\">':'</span>, fdist[m], end=<span class=\"pysrc-string\">' '</span>)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">can: 94 could: 87 may: 93 might: 38 must: 53 will: 389</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\">We need to include <tt class=\"doctest\"><span class=\"pre\">end=<span class=\"pysrc-string\">' '</span></span></tt> in order for the print function to\n",
      "put its output on a single line.</p>\n",
      "</div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Your Turn:</strong>\n",
      "Choose a different section of the Brown Corpus, and adapt the previous\n",
      "example to count a selection of <span class=\"example\">wh</span> words, such as <span class=\"example\">what</span>,\n",
      "<span class=\"example\">when</span>, <span class=\"example\">where</span>, <span class=\"example\">who</span>, and <span class=\"example\">why</span>.</p>\n",
      "</div>\n",
      "</a><p><a name=\"stylistics_index_term\">Next, we need to obtain counts for each genre of interest.  We'll use\n",
      "NLTK's support for conditional frequency distributions. These are\n",
      "presented systematically in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#sec-conditional-frequency-distributions\">2</a>,\n",
      "where we also unpick the following code line by line. For the moment,\n",
      "you can ignore the details and just concentrate on the output.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (genre, word)\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> genre <span class=\"pysrc-keyword\">in</span> brown.categories()\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> word <span class=\"pysrc-keyword\">in</span> brown.words(categories=genre))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>genres = [<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'religion'</span>, <span class=\"pysrc-string\">'hobbies'</span>, <span class=\"pysrc-string\">'science_fiction'</span>, <span class=\"pysrc-string\">'romance'</span>, <span class=\"pysrc-string\">'humor'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>modals = [<span class=\"pysrc-string\">'can'</span>, <span class=\"pysrc-string\">'could'</span>, <span class=\"pysrc-string\">'may'</span>, <span class=\"pysrc-string\">'might'</span>, <span class=\"pysrc-string\">'must'</span>, <span class=\"pysrc-string\">'will'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.tabulate(conditions=genres, samples=modals)\n",
      "<span class=\"pysrc-output\">                 can could  may might must will</span>\n",
      "<span class=\"pysrc-output\">           news   93   86   66   38   50  389</span>\n",
      "<span class=\"pysrc-output\">       religion   82   59   78   12   54   71</span>\n",
      "<span class=\"pysrc-output\">        hobbies  268   58  131   22   83  264</span>\n",
      "<span class=\"pysrc-output\">science_fiction   16   49    4   12    8   16</span>\n",
      "<span class=\"pysrc-output\">        romance   74  193   11   51   45   43</span>\n",
      "<span class=\"pysrc-output\">          humor   16   30    8    8    9   13</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Observe that the most frequent modal in the news genre is <span class=\"example\">will</span>,\n",
      "while the most frequent modal in the romance genre is <span class=\"example\">could</span>.\n",
      "Would you have predicted this?  The idea that word counts\n",
      "might distinguish genres will be taken up again in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch06.html#chap-data-intensive\">chap-data-intensive</a>.</p>\n",
      "<!-- XXX xref isn't being handled? -->\n",
      "</div>\n",
      "<div class=\"section\" id=\"reuters-corpus\">\n",
      "<h2>1.4&nbsp;&nbsp;&nbsp;Reuters Corpus</h2>\n",
      "<p>The Reuters Corpus contains 10,788 news documents totaling 1.3 million words.\n",
      "The documents have been classified into 90 topics, and grouped\n",
      "into two sets, called \"training\" and \"test\"; thus, the text with\n",
      "fileid <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'test/14826'</span></span></tt> is a document drawn from the test set. This split is for\n",
      "training and testing algorithms that automatically detect the topic of a document,\n",
      "as we will see in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch06.html#chap-data-intensive\">chap-data-intensive</a>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> reuters\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.fileids()\n",
      "<span class=\"pysrc-output\">['test/14826', 'test/14828', 'test/14829', 'test/14832', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.categories()\n",
      "<span class=\"pysrc-output\">['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa',</span>\n",
      "<span class=\"pysrc-output\">'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn',</span>\n",
      "<span class=\"pysrc-output\">'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Unlike the Brown Corpus, categories in the Reuters corpus overlap with\n",
      "each other, simply because a news story often covers multiple topics.\n",
      "We can ask for the topics covered by one or more documents, or for the\n",
      "documents included in one or more categories. For convenience, the\n",
      "corpus methods accept a single fileid or a list of fileids.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.categories(<span class=\"pysrc-string\">'training/9865'</span>)\n",
      "<span class=\"pysrc-output\">['barley', 'corn', 'grain', 'wheat']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.categories([<span class=\"pysrc-string\">'training/9865'</span>, <span class=\"pysrc-string\">'training/9880'</span>])\n",
      "<span class=\"pysrc-output\">['barley', 'corn', 'grain', 'money-fx', 'wheat']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.fileids(<span class=\"pysrc-string\">'barley'</span>)\n",
      "<span class=\"pysrc-output\">['test/15618', 'test/15649', 'test/15676', 'test/15728', 'test/15871', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.fileids([<span class=\"pysrc-string\">'barley'</span>, <span class=\"pysrc-string\">'corn'</span>])\n",
      "<span class=\"pysrc-output\">['test/14832', 'test/14858', 'test/15033', 'test/15043', 'test/15106',</span>\n",
      "<span class=\"pysrc-output\">'test/15287', 'test/15341', 'test/15618', 'test/15648', 'test/15649', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Similarly, we can specify the words or sentences we want in terms of\n",
      "files or categories. The first handful of words in each of these texts are the\n",
      "titles, which by convention are stored as upper case.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.words(<span class=\"pysrc-string\">'training/9865'</span>)[:14]\n",
      "<span class=\"pysrc-output\">['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', 'BIDS',</span>\n",
      "<span class=\"pysrc-output\">'DETAILED', 'French', 'operators', 'have', 'requested', 'licences', 'to', 'export']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.words([<span class=\"pysrc-string\">'training/9865'</span>, <span class=\"pysrc-string\">'training/9880'</span>])\n",
      "<span class=\"pysrc-output\">['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.words(categories=<span class=\"pysrc-string\">'barley'</span>)\n",
      "<span class=\"pysrc-output\">['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>reuters.words(categories=[<span class=\"pysrc-string\">'barley'</span>, <span class=\"pysrc-string\">'corn'</span>])\n",
      "<span class=\"pysrc-output\">['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"inaugural-address-corpus\">\n",
      "<h2>1.5&nbsp;&nbsp;&nbsp;Inaugural Address Corpus</h2>\n",
      "<!-- XXX fig-inaugural_ isn't being handled correctly in the output -->\n",
      "<p>In <a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>, we looked at\n",
      "the Inaugural Address Corpus,\n",
      "but treated it as a single text.  The graph in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#fig-inaugural\">fig-inaugural</a>\n",
      "used \"word offset\" as one of the axes; this is the numerical index of the\n",
      "word in the corpus, counting from the first word of the first address.\n",
      "However, the corpus is actually a collection of 55 texts, one for each presidential address.\n",
      "An interesting property of this collection is its time dimension:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> inaugural\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>inaugural.fileids()\n",
      "<span class=\"pysrc-output\">['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[fileid[:4] <span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> inaugural.fileids()]\n",
      "<span class=\"pysrc-output\">['1789', '1793', '1797', '1801', '1805', '1809', '1813', '1817', '1821', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Notice that the year of each text appears in its filename.  To get the year\n",
      "out of the filename, we extracted the first four characters, using <tt class=\"doctest\"><span class=\"pre\">fileid[:4]</span></tt>.</p>\n",
      "<p>Let's look at how the words <span class=\"example\">America</span> and <span class=\"example\">citizen</span> are used over time.\n",
      "The following code\n",
      "converts the words in the Inaugural corpus\n",
      "to lowercase using <tt class=\"doctest\"><span class=\"pre\">w.lower()</span></tt> <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#lowercase-startswith\"><span id=\"ref-lowercase-startswith\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>,\n",
      "then checks if they start with either of the \"targets\"\n",
      "<tt class=\"doctest\"><span class=\"pre\">america</span></tt> or <tt class=\"doctest\"><span class=\"pre\">citizen</span></tt> using <tt class=\"doctest\"><span class=\"pre\">startswith()</span></tt> <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#lowercase-startswith\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>.\n",
      "Thus it will count words like <span class=\"example\">American's</span> and <span class=\"example\">Citizens</span>.\n",
      "We'll learn about conditional frequency distributions in\n",
      "<a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#sec-conditional-frequency-distributions\">2</a>; for now just consider\n",
      "the output, shown in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-inaugural2\">1.1</a>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (target, fileid[:4])\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> inaugural.fileids()\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> inaugural.words(fileid)\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> target <span class=\"pysrc-keyword\">in</span> [<span class=\"pysrc-string\">'america'</span>, <span class=\"pysrc-string\">'citizen'</span>]\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">if</span> w.lower().startswith(target)) <a name=\"lowercase-startswith\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-lowercase-startswith\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.plot()</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<span class=\"target\" id=\"fig-inaugural2\"></span><div class=\"figure\" id=\"fig-inaugural2\">\n",
      "<img alt=\"../images/inaugural2.png\" src=\"./kadai3_files/inaugural2.png\" style=\"width: 646.74px; height: 292.32px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 1.1</span>: Plot of a Conditional Frequency Distribution: all words in the Inaugural Address\n",
      "Corpus that begin with <tt class=\"doctest\"><span class=\"pre\">america</span></tt> or <tt class=\"doctest\"><span class=\"pre\">citizen</span></tt> are counted; separate counts\n",
      "are kept for each address; these are plotted so that trends in usage over time can\n",
      "be observed; counts are not normalized for document length.</p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"annotated-text-corpora\">\n",
      "<h2>1.6&nbsp;&nbsp;&nbsp;Annotated Text Corpora</h2>\n",
      "<p>Many text corpora contain linguistic annotations, representing POS tags,\n",
      "named entities, syntactic structures, semantic roles, and so forth.  NLTK provides\n",
      "convenient ways to access several of these corpora, and has data packages containing corpora\n",
      "and corpus samples, freely downloadable for use in teaching and research.\n",
      "<a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#tab-corpora\">1.2</a> lists some of the corpora.  For information about\n",
      "downloading them, see <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/data</span></tt>.\n",
      "For more examples of how to access NLTK corpora,\n",
      "please consult the Corpus HOWTO at <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/howto</span></tt>.</p>\n",
      "<span class=\"target\" id=\"tab-corpora\"></span><p class=\"caption\"><span class=\"caption-label\">Table 1.2</span>: </p><p>Some of the Corpora and Corpus Samples Distributed with NLTK: For information about downloading\n",
      "and using them, please consult the NLTK website.</p><p></p><table border=\"1\" class=\"docutils\" id=\"tab-corpora\">\n",
      "<colgroup>\n",
      "<col width=\"31%\">\n",
      "<col width=\"18%\">\n",
      "<col width=\"51%\">\n",
      "</colgroup>\n",
      "<thead valign=\"bottom\">\n",
      "<tr><th class=\"head\">Corpus</th>\n",
      "<th class=\"head\">Compiler</th>\n",
      "<th class=\"head\">Contents</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<tr><td>Brown Corpus</td>\n",
      "<td>Francis, Kucera</td>\n",
      "<td>15 genres, 1.15M words, tagged, categorized</td>\n",
      "</tr>\n",
      "<tr><td>CESS Treebanks</td>\n",
      "<td>CLiC-UB</td>\n",
      "<td>1M words, tagged and parsed (Catalan, Spanish)</td>\n",
      "</tr>\n",
      "<tr><td>Chat-80 Data Files</td>\n",
      "<td>Pereira &amp; Warren</td>\n",
      "<td>World Geographic Database</td>\n",
      "</tr>\n",
      "<tr><td>CMU Pronouncing Dictionary</td>\n",
      "<td>CMU</td>\n",
      "<td>127k entries</td>\n",
      "</tr>\n",
      "<tr><td>CoNLL 2000 Chunking Data</td>\n",
      "<td>CoNLL</td>\n",
      "<td>270k words, tagged and chunked</td>\n",
      "</tr>\n",
      "<tr><td>CoNLL 2002 Named Entity</td>\n",
      "<td>CoNLL</td>\n",
      "<td>700k words, pos- and named-entity-tagged (Dutch, Spanish)</td>\n",
      "</tr>\n",
      "<tr><td>CoNLL 2007 Dependency Treebanks (sel)</td>\n",
      "<td>CoNLL</td>\n",
      "<td>150k words, dependency parsed (Basque, Catalan)</td>\n",
      "</tr>\n",
      "<tr><td>Dependency Treebank</td>\n",
      "<td>Narad</td>\n",
      "<td>Dependency parsed version of Penn Treebank sample</td>\n",
      "</tr>\n",
      "<tr><td>FrameNet</td>\n",
      "<td>Fillmore, Baker et al</td>\n",
      "<td>10k word senses, 170k manually annotated sentences</td>\n",
      "</tr>\n",
      "<tr><td>Floresta Treebank</td>\n",
      "<td>Diana Santos et al</td>\n",
      "<td>9k sentences, tagged and parsed (Portuguese)</td>\n",
      "</tr>\n",
      "<tr><td>Gazetteer Lists</td>\n",
      "<td>Various</td>\n",
      "<td>Lists of cities and countries</td>\n",
      "</tr>\n",
      "<tr><td>Genesis Corpus</td>\n",
      "<td>Misc web sources</td>\n",
      "<td>6 texts, 200k words, 6 languages</td>\n",
      "</tr>\n",
      "<tr><td>Gutenberg (selections)</td>\n",
      "<td>Hart, Newby, et al</td>\n",
      "<td>18 texts, 2M words</td>\n",
      "</tr>\n",
      "<tr><td>Inaugural Address Corpus</td>\n",
      "<td>CSpan</td>\n",
      "<td>US Presidential Inaugural Addresses (1789-present)</td>\n",
      "</tr>\n",
      "<tr><td>Indian POS-Tagged Corpus</td>\n",
      "<td>Kumaran et al</td>\n",
      "<td>60k words, tagged (Bangla, Hindi, Marathi, Telugu)</td>\n",
      "</tr>\n",
      "<tr><td>MacMorpho Corpus</td>\n",
      "<td>NILC, USP, Brazil</td>\n",
      "<td>1M words, tagged (Brazilian Portuguese)</td>\n",
      "</tr>\n",
      "<tr><td>Movie Reviews</td>\n",
      "<td>Pang, Lee</td>\n",
      "<td>2k movie reviews with sentiment polarity classification</td>\n",
      "</tr>\n",
      "<tr><td>Names Corpus</td>\n",
      "<td>Kantrowitz, Ross</td>\n",
      "<td>8k male and female names</td>\n",
      "</tr>\n",
      "<tr><td>NIST 1999 Info Extr (selections)</td>\n",
      "<td>Garofolo</td>\n",
      "<td>63k words, newswire and named-entity SGML markup</td>\n",
      "</tr>\n",
      "<tr><td>Nombank</td>\n",
      "<td>Meyers</td>\n",
      "<td>115k propositions, 1400 noun frames</td>\n",
      "</tr>\n",
      "<tr><td>NPS Chat Corpus</td>\n",
      "<td>Forsyth, Martell</td>\n",
      "<td>10k IM chat posts, POS-tagged and dialogue-act tagged</td>\n",
      "</tr>\n",
      "<tr><td>Open Multilingual WordNet</td>\n",
      "<td>Bond et al</td>\n",
      "<td>15 languages, aligned to English WordNet</td>\n",
      "</tr>\n",
      "<tr><td>PP Attachment Corpus</td>\n",
      "<td>Ratnaparkhi</td>\n",
      "<td>28k prepositional phrases, tagged as noun or verb modifiers</td>\n",
      "</tr>\n",
      "<tr><td>Proposition Bank</td>\n",
      "<td>Palmer</td>\n",
      "<td>113k propositions, 3300 verb frames</td>\n",
      "</tr>\n",
      "<tr><td>Question Classification</td>\n",
      "<td>Li, Roth</td>\n",
      "<td>6k questions, categorized</td>\n",
      "</tr>\n",
      "<tr><td>Reuters Corpus</td>\n",
      "<td>Reuters</td>\n",
      "<td>1.3M words, 10k news documents, categorized</td>\n",
      "</tr>\n",
      "<tr><td>Roget's Thesaurus</td>\n",
      "<td>Project Gutenberg</td>\n",
      "<td>200k words, formatted text</td>\n",
      "</tr>\n",
      "<tr><td>RTE Textual Entailment</td>\n",
      "<td>Dagan et al</td>\n",
      "<td>8k sentence pairs, categorized</td>\n",
      "</tr>\n",
      "<tr><td>SEMCOR</td>\n",
      "<td>Rus, Mihalcea</td>\n",
      "<td>880k words, part-of-speech and sense tagged</td>\n",
      "</tr>\n",
      "<tr><td>Senseval 2 Corpus</td>\n",
      "<td>Pedersen</td>\n",
      "<td>600k words, part-of-speech and sense tagged</td>\n",
      "</tr>\n",
      "<tr><td>SentiWordNet</td>\n",
      "<td>Esuli, Sebastiani</td>\n",
      "<td>sentiment scores for 145k WordNet synonym sets</td>\n",
      "</tr>\n",
      "<tr><td>Shakespeare texts (selections)</td>\n",
      "<td>Bosak</td>\n",
      "<td>8 books in XML format</td>\n",
      "</tr>\n",
      "<tr><td>State of the Union Corpus</td>\n",
      "<td>CSPAN</td>\n",
      "<td>485k words, formatted text</td>\n",
      "</tr>\n",
      "<tr><td>Stopwords Corpus</td>\n",
      "<td>Porter et al</td>\n",
      "<td>2,400 stopwords for 11 languages</td>\n",
      "</tr>\n",
      "<tr><td>Swadesh Corpus</td>\n",
      "<td>Wiktionary</td>\n",
      "<td>comparative wordlists in 24 languages</td>\n",
      "</tr>\n",
      "<tr><td>Switchboard Corpus (selections)</td>\n",
      "<td>LDC</td>\n",
      "<td>36 phonecalls, transcribed, parsed</td>\n",
      "</tr>\n",
      "<tr><td>Univ Decl of Human Rights</td>\n",
      "<td>United Nations</td>\n",
      "<td>480k words, 300+ languages</td>\n",
      "</tr>\n",
      "<tr><td>Penn Treebank (selections)</td>\n",
      "<td>LDC</td>\n",
      "<td>40k words, tagged and parsed</td>\n",
      "</tr>\n",
      "<tr><td>TIMIT Corpus (selections)</td>\n",
      "<td>NIST/LDC</td>\n",
      "<td>audio files and transcripts for 16 speakers</td>\n",
      "</tr>\n",
      "<tr><td>VerbNet 2.1</td>\n",
      "<td>Palmer et al</td>\n",
      "<td>5k verbs, hierarchically organized, linked to WordNet</td>\n",
      "</tr>\n",
      "<tr><td>Wordlist Corpus</td>\n",
      "<td>OpenOffice.org et al</td>\n",
      "<td>960k words and 20k affixes for 8 languages</td>\n",
      "</tr>\n",
      "<tr><td>WordNet 3.0 (English)</td>\n",
      "<td>Miller, Fellbaum</td>\n",
      "<td>145k synonym sets</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "\n",
      "\n",
      "</table>\n",
      "</div>\n",
      "<div class=\"section\" id=\"corpora-in-other-languages\">\n",
      "<h2>1.7&nbsp;&nbsp;&nbsp;Corpora in Other Languages</h2>\n",
      "<p>NLTK comes with corpora for many languages, though in some cases\n",
      "you will need to learn how to manipulate character encodings in Python\n",
      "before using these corpora (see <a class=\"reference external\" href=\"https://www.nltk.org/book/ch03.html#sec-unicode\">3.3</a>).</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.cess_esp.words()\n",
      "<span class=\"pysrc-output\">['El', 'grupo', 'estatal', 'Electricit\\xe9_de_France', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.floresta.words()\n",
      "<span class=\"pysrc-output\">['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.indian.words(<span class=\"pysrc-string\">'hindi.pos'</span>)\n",
      "<span class=\"pysrc-output\">['पूर्ण', 'प्रतिबंध', 'हटाओ', ':', 'इराक', 'संयुक्त', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.udhr.fileids()\n",
      "<span class=\"pysrc-output\">['Abkhaz-Cyrillic+Abkh', 'Abkhaz-UTF8', 'Achehnese-Latin1', 'Achuar-Shiwiar-Latin1',</span>\n",
      "<span class=\"pysrc-output\">'Adja-UTF8', 'Afaan_Oromo_Oromiffa-Latin1', 'Afrikaans-Latin1', 'Aguaruna-Latin1',</span>\n",
      "<span class=\"pysrc-output\">'Akuapem_Twi-UTF8', 'Albanian_Shqip-Latin1', 'Amahuaca', 'Amahuaca-Latin1', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>nltk.corpus.udhr.words(<span class=\"pysrc-string\">'Javanese-Latin1'</span>)[11:]\n",
      "<span class=\"pysrc-output\">['Saben', 'umat', 'manungsa', 'lair', 'kanthi', 'hak', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The last of these corpora, <tt class=\"doctest\"><span class=\"pre\">udhr</span></tt>, contains the Universal Declaration of Human Rights\n",
      "in over 300 languages.  The fileids for this corpus include\n",
      "information about the character encoding used in the file,\n",
      "such as <tt class=\"doctest\"><span class=\"pre\">UTF8</span></tt> or <tt class=\"doctest\"><span class=\"pre\">Latin1</span></tt>.\n",
      "Let's use a conditional frequency distribution to examine the differences in word lengths\n",
      "for a selection of languages included in the <tt class=\"doctest\"><span class=\"pre\">udhr</span></tt> corpus.\n",
      "The output is shown in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-word-len-dist\">1.2</a> (run the program yourself to see a color plot).\n",
      "Note that <tt class=\"doctest\"><span class=\"pre\">True</span></tt> and <tt class=\"doctest\"><span class=\"pre\">False</span></tt> are Python's built-in boolean values.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> udhr\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>languages = [<span class=\"pysrc-string\">'Chickasaw'</span>, <span class=\"pysrc-string\">'English'</span>, <span class=\"pysrc-string\">'German_Deutsch'</span>,\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-string\">'Greenlandic_Inuktikut'</span>, <span class=\"pysrc-string\">'Hungarian_Magyar'</span>, <span class=\"pysrc-string\">'Ibibio_Efik'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (lang, len(word))\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> lang <span class=\"pysrc-keyword\">in</span> languages\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> word <span class=\"pysrc-keyword\">in</span> udhr.words(lang + <span class=\"pysrc-string\">'-Latin1'</span>))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.plot(cumulative=True)</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<span class=\"target\" id=\"fig-word-len-dist\"></span><div class=\"figure\" id=\"fig-word-len-dist\">\n",
      "<img alt=\"../images/word-len-dist.png\" src=\"./kadai3_files/word-len-dist.png\" style=\"width: 613.0px; height: 463.0px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 1.2</span>: Cumulative Word Length Distributions:\n",
      "Six translations of the Universal Declaration of Human Rights are processed;\n",
      "this graph shows that words having 5 or fewer letters account for about\n",
      "80% of Ibibio text, 60% of German text, and 25% of Inuktitut text.</p>\n",
      "</div>\n",
      "<!-- XXX In the following, nltk.FreqDist got wrapped weirdly (as FreqD-ist) -->\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Your Turn:</strong>\n",
      "Pick a language of interest in <tt class=\"doctest\"><span class=\"pre\">udhr.fileids()</span></tt>, and define a variable\n",
      "<tt class=\"doctest\"><span class=\"pre\">raw_text = udhr.raw(</span></tt><em>Language-Latin1</em><tt class=\"doctest\"><span class=\"pre\">)</span></tt>.  Now plot a frequency\n",
      "distribution of the letters of the text using <tt class=\"doctest\"><span class=\"pre\">nltk.FreqDist(raw_text).plot()</span></tt>.</p>\n",
      "</div>\n",
      "<p>Unfortunately, for many languages, substantial corpora are not yet available.  Often there is\n",
      "insufficient government or industrial support for developing language resources, and individual\n",
      "efforts are piecemeal and hard to discover or re-use.  Some languages have no\n",
      "established writing system, or are endangered.  (See <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#sec-further-reading-corpora\">7</a>\n",
      "for suggestions on how to locate language resources.)</p>\n",
      "</div>\n",
      "<div class=\"section\" id=\"text-corpus-structure\">\n",
      "<h2>1.8&nbsp;&nbsp;&nbsp;Text Corpus Structure</h2>\n",
      "<p>We have seen a variety of corpus structures so far; these are\n",
      "summarized in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-text-corpus-structure\">1.3</a>.\n",
      "The simplest kind lacks any structure: it is just a collection of texts.\n",
      "Often, texts are grouped into categories that might correspond to genre, source, author, language, etc.\n",
      "Sometimes these categories overlap, notably in the case of topical categories as a text can be\n",
      "relevant to more than one topic.  Occasionally, text collections have temporal structure,\n",
      "news collections being the most common example.</p>\n",
      "<span class=\"target\" id=\"fig-text-corpus-structure\"></span><div class=\"figure\" id=\"fig-text-corpus-structure\">\n",
      "<img alt=\"../images/text-corpus-structure.png\" src=\"./kadai3_files/text-corpus-structure.png\" style=\"width: 607.1999999999999px; height: 129.6px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 1.3</span>: Common Structures for Text Corpora: The simplest kind of corpus is a collection\n",
      "of isolated texts with no particular organization; some corpora are structured\n",
      "into categories like genre (Brown Corpus); some categorizations overlap, such as\n",
      "topic categories (Reuters Corpus); other corpora represent language use over time\n",
      "(Inaugural Address Corpus).</p>\n",
      "</div>\n",
      "<span class=\"target\" id=\"tab-corpus\"></span><p class=\"caption\"><span class=\"caption-label\">Table 1.3</span>: </p><p>Basic Corpus Functionality defined in NLTK: more documentation can be found using\n",
      "<tt class=\"doctest\"><span class=\"pre\">help(nltk.corpus.reader)</span></tt> and by reading the online Corpus HOWTO at <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/howto</span></tt>.</p><p></p><table border=\"1\" class=\"docutils\" id=\"tab-corpus\">\n",
      "<colgroup>\n",
      "<col width=\"35%\">\n",
      "<col width=\"65%\">\n",
      "</colgroup>\n",
      "<thead valign=\"bottom\">\n",
      "<tr><th class=\"head\">Example</th>\n",
      "<th class=\"head\">Description</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">fileids()</span></tt></td>\n",
      "<td>the files of the corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">fileids([categories])</span></tt></td>\n",
      "<td>the files of the corpus corresponding to these categories</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">categories()</span></tt></td>\n",
      "<td>the categories of the corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">categories([fileids])</span></tt></td>\n",
      "<td>the categories of the corpus corresponding to these files</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">raw()</span></tt></td>\n",
      "<td>the raw content of the corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">raw(fileids=[f1,f2,f3])</span></tt></td>\n",
      "<td>the raw content of the specified files</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">raw(categories=[c1,c2])</span></tt></td>\n",
      "<td>the raw content of the specified categories</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">words()</span></tt></td>\n",
      "<td>the words of the whole corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">words(fileids=[f1,f2,f3])</span></tt></td>\n",
      "<td>the words of the specified fileids</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">words(categories=[c1,c2])</span></tt></td>\n",
      "<td>the words of the specified categories</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">sents()</span></tt></td>\n",
      "<td>the sentences of the whole corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">sents(fileids=[f1,f2,f3])</span></tt></td>\n",
      "<td>the sentences of the specified fileids</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">sents(categories=[c1,c2])</span></tt></td>\n",
      "<td>the sentences of the specified categories</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">abspath(fileid)</span></tt></td>\n",
      "<td>the location of the given file on disk</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">encoding(fileid)</span></tt></td>\n",
      "<td>the encoding of the file (if known)</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">open(fileid)</span></tt></td>\n",
      "<td>open a stream for reading the given corpus file</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">root</span></tt></td>\n",
      "<td>if the path to the root of locally installed corpus</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">readme()</span></tt></td>\n",
      "<td>the contents of the README file of the corpus</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "\n",
      "\n",
      "</table>\n",
      "<p>NLTK's corpus readers support efficient access to a variety of corpora, and can\n",
      "be used to work with new corpora.  <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#tab-corpus\">1.3</a> lists functionality\n",
      "provided by the corpus readers.  We illustrate the difference between some\n",
      "of the corpus access methods below:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>raw = gutenberg.raw(<span class=\"pysrc-string\">\"burgess-busterbrown.txt\"</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>raw[1:20]\n",
      "<span class=\"pysrc-output\">'The Adventures of B'</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>words = gutenberg.words(<span class=\"pysrc-string\">\"burgess-busterbrown.txt\"</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>words[1:20]\n",
      "<span class=\"pysrc-output\">['The', 'Adventures', 'of', 'Buster', 'Bear', 'by', 'Thornton', 'W', '.',</span>\n",
      "<span class=\"pysrc-output\">'Burgess', '1920', ']', 'I', 'BUSTER', 'BEAR', 'GOES', 'FISHING', 'Buster',</span>\n",
      "<span class=\"pysrc-output\">'Bear']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>sents = gutenberg.sents(<span class=\"pysrc-string\">\"burgess-busterbrown.txt\"</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>sents[1:20]\n",
      "<span class=\"pysrc-output\">[['I'], ['BUSTER', 'BEAR', 'GOES', 'FISHING'], ['Buster', 'Bear', 'yawned', 'as',</span>\n",
      "<span class=\"pysrc-output\">'he', 'lay', 'on', 'his', 'comfortable', 'bed', 'of', 'leaves', 'and', 'watched',</span>\n",
      "<span class=\"pysrc-output\">'the', 'first', 'early', 'morning', 'sunbeams', 'creeping', 'through', ...], ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"loading-your-own-corpus\">\n",
      "<h2>1.9&nbsp;&nbsp;&nbsp;Loading your own Corpus</h2>\n",
      "<p>If you have your own collection of text files that you would like to access using\n",
      "the above methods, you can easily load them with the help of NLTK's\n",
      "<tt class=\"doctest\"><span class=\"pre\">PlaintextCorpusReader</span></tt>. Check the location of your files on your file system; in\n",
      "the following example, we have taken this to be the directory\n",
      "<tt class=\"doctest\"><span class=\"pre\">/usr/share/dict</span></tt>. Whatever the location, set this to be the value of\n",
      "<tt class=\"doctest\"><span class=\"pre\">corpus_root</span></tt> <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#corpus-root-dict\"><span id=\"ref-corpus-root-dict\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.\n",
      "The second parameter of the <tt class=\"doctest\"><span class=\"pre\">PlaintextCorpusReader</span></tt> initializer <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#corpus-reader\"><span id=\"ref-corpus-reader\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>\n",
      "can be a list of fileids, like <tt class=\"doctest\"><span class=\"pre\">[<span class=\"pysrc-string\">'a.txt'</span>, <span class=\"pysrc-string\">'test/b.txt'</span>]</span></tt>,\n",
      "or a pattern that matches all fileids, like <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'[abc]/.*\\.txt'</span></span></tt>\n",
      "(see <a class=\"reference external\" href=\"https://www.nltk.org/book/ch03.html#sec-regular-expressions-word-patterns\">3.4</a> for information\n",
      "about regular expressions).</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> PlaintextCorpusReader\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>corpus_root = <span class=\"pysrc-string\">'/usr/share/dict'</span> <a name=\"corpus-root-dict\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-corpus-root-dict\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wordlists = PlaintextCorpusReader(corpus_root, <span class=\"pysrc-string\">'.*'</span>) <a name=\"corpus-reader\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-corpus-reader\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wordlists.fileids()\n",
      "<span class=\"pysrc-output\">['README', 'connectives', 'propernames', 'web2', 'web2a', 'words']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wordlists.words(<span class=\"pysrc-string\">'connectives'</span>)\n",
      "<span class=\"pysrc-output\">['the', 'of', 'and', 'to', 'a', 'in', 'that', 'is', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>As another example, suppose you have your own local copy of Penn Treebank (release 3),\n",
      "in <tt class=\"doctest\"><span class=\"pre\">C:\\corpora</span></tt>.  We can use the <tt class=\"doctest\"><span class=\"pre\">BracketParseCorpusReader</span></tt> to access this\n",
      "corpus.  We specify the <tt class=\"doctest\"><span class=\"pre\">corpus_root</span></tt> to be the location of the parsed Wall Street\n",
      "Journal component of the corpus <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#corpus-root-treebank\"><span id=\"ref-corpus-root-treebank\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>, and give a <tt class=\"doctest\"><span class=\"pre\">file_pattern</span></tt>\n",
      "that matches the files contained within its subfolders <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#file-pattern\"><span id=\"ref-file-pattern\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a> (using forward slashes).</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> BracketParseCorpusReader\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>corpus_root = r<span class=\"pysrc-string\">\"C:\\corpora\\penntreebank\\parsed\\mrg\\wsj\"</span> <a name=\"corpus-root-treebank\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-corpus-root-treebank\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>file_pattern = r<span class=\"pysrc-string\">\".*/wsj_.*\\.mrg\"</span> <a name=\"file-pattern\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-file-pattern\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>ptb = BracketParseCorpusReader(corpus_root, file_pattern)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>ptb.fileids()\n",
      "<span class=\"pysrc-output\">['00/wsj_0001.mrg', '00/wsj_0002.mrg', '00/wsj_0003.mrg', '00/wsj_0004.mrg', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>len(ptb.sents())\n",
      "<span class=\"pysrc-output\">49208</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>ptb.sents(fileids=<span class=\"pysrc-string\">'20/wsj_2013.mrg'</span>)[19]\n",
      "<span class=\"pysrc-output\">['The', '55-year-old', 'Mr.', 'Noriega', 'is', \"n't\", 'as', 'smooth', 'as', 'the',</span>\n",
      "<span class=\"pysrc-output\">'shah', 'of', 'Iran', ',', 'as', 'well-born', 'as', 'Nicaragua', \"'s\", 'Anastasio',</span>\n",
      "<span class=\"pysrc-output\">'Somoza', ',', 'as', 'imperial', 'as', 'Ferdinand', 'Marcos', 'of', 'the', 'Philippines',</span>\n",
      "<span class=\"pysrc-output\">'or', 'as', 'bloody', 'as', 'Haiti', \"'s\", 'Baby', Doc', 'Duvalier', '.']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"conditional-frequency-distributions\">\n",
      "<span id=\"sec-conditional-frequency-distributions\"></span><h1>2&nbsp;&nbsp;&nbsp;Conditional Frequency Distributions</h1>\n",
      "<p>We introduced frequency distributions in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-simple-statistics\">3</a>.\n",
      "We saw that given some list <tt class=\"doctest\"><span class=\"pre\">mylist</span></tt> of words or other items,\n",
      "<tt class=\"doctest\"><span class=\"pre\">FreqDist(mylist)</span></tt> would compute the number of occurrences of each\n",
      "item in the list.  Here we will generalize this idea.</p>\n",
      "<p>When the texts of a corpus are divided into several\n",
      "categories, by genre, topic, author, etc, we can maintain separate\n",
      "frequency distributions for each category.  This will allow us to\n",
      "study systematic differences between the categories.  In the previous\n",
      "section we achieved this using NLTK's <tt class=\"doctest\"><span class=\"pre\">ConditionalFreqDist</span></tt> data\n",
      "type.  A <a name=\"conditional_frequency_distribution_index_term\"><span class=\"termdef\">conditional frequency distribution</span> is a collection of\n",
      "frequency distributions, each one for a different \"condition\".  The\n",
      "condition will often be the category of the text.  </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-tally2\">2.1</a>\n",
      "depicts a fragment of a conditional frequency distribution having just\n",
      "two conditions, one for news text and one for romance text.</p>\n",
      "<span class=\"target\" id=\"fig-tally2\"></span><div class=\"figure\" id=\"fig-tally2\">\n",
      "<img alt=\"../images/tally2.png\" src=\"./kadai3_files/tally2.png\" style=\"width: 412.29999999999995px; height: 130.2px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 2.1</span>: Counting Words Appearing in a Text Collection (a conditional frequency distribution)</p>\n",
      "</div>\n",
      "<div class=\"section\" id=\"conditions-and-events\">\n",
      "<h2>2.1&nbsp;&nbsp;&nbsp;Conditions and Events</h2>\n",
      "<p>A frequency distribution counts observable events,\n",
      "such as the appearance of words in a text.  A conditional\n",
      "frequency distribution needs to pair each event with a condition.\n",
      "So instead of processing a sequence of words <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#seq-words\"><span id=\"ref-seq-words\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>,\n",
      "we have to process a sequence of pairs <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#seq-pairs\"><span id=\"ref-seq-pairs\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>text = [<span class=\"pysrc-string\">'The'</span>, <span class=\"pysrc-string\">'Fulton'</span>, <span class=\"pysrc-string\">'County'</span>, <span class=\"pysrc-string\">'Grand'</span>, <span class=\"pysrc-string\">'Jury'</span>, <span class=\"pysrc-string\">'said'</span>, ...] <a name=\"seq-words\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-seq-words\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>pairs = [(<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'The'</span>), (<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'Fulton'</span>), (<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'County'</span>), ...] <a name=\"seq-pairs\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-seq-pairs\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Each pair has the form <tt class=\"doctest\"><span class=\"pre\">(condition, event)</span></tt>.  If we were processing the\n",
      "entire Brown Corpus by genre there would be 15 conditions (one per genre),\n",
      "and 1,161,192 events (one per word).</p>\n",
      "</div>\n",
      "<div class=\"section\" id=\"counting-words-by-genre\">\n",
      "<h2>2.2&nbsp;&nbsp;&nbsp;Counting Words by Genre</h2>\n",
      "<p>In <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#sec-extracting-text-from-corpora\">1</a> we saw a conditional\n",
      "frequency distribution where the condition was the section of the\n",
      "Brown Corpus, and for each condition we counted words. Whereas\n",
      "<tt class=\"doctest\"><span class=\"pre\">FreqDist()</span></tt> takes a simple list as input, <tt class=\"doctest\"><span class=\"pre\">ConditionalFreqDist()</span></tt>\n",
      "takes a list of pairs.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> brown\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (genre, word)\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> genre <span class=\"pysrc-keyword\">in</span> brown.categories()\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> word <span class=\"pysrc-keyword\">in</span> brown.words(categories=genre))</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Let's break this down, and look at just two genres, news and romance.\n",
      "For each genre <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#each-genre\"><span id=\"ref-each-genre\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>, we loop over every word in the genre <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#each-word\"><span id=\"ref-each-word\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></span></a>,\n",
      "producing pairs consisting of the genre and the word <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#genre-word-pairs\"><span id=\"ref-genre-word-pairs\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>genre_word = [(genre, word) <a name=\"genre-word-pairs\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-genre-word-pairs\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>              <span class=\"pysrc-keyword\">for</span> genre <span class=\"pysrc-keyword\">in</span> [<span class=\"pysrc-string\">'news'</span>, <span class=\"pysrc-string\">'romance'</span>] <a name=\"each-genre\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-each-genre\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>              <span class=\"pysrc-keyword\">for</span> word <span class=\"pysrc-keyword\">in</span> brown.words(categories=genre)] <a name=\"each-word\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-each-word\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>len(genre_word)\n",
      "<span class=\"pysrc-output\">170576</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>So, as we can see below,\n",
      "pairs at the beginning of the list <tt class=\"doctest\"><span class=\"pre\">genre_word</span></tt> will be of the form\n",
      "(<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'news'</span></span></tt>, <em>word</em>) <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#start-genre\"><span id=\"ref-start-genre\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>, while those at the end will be of the form\n",
      "(<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'romance'</span></span></tt>, <em>word</em>) <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#end-genre\"><span id=\"ref-end-genre\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>genre_word[:4]\n",
      "<span class=\"pysrc-output\">[('news', 'The'), ('news', 'Fulton'), ('news', 'County'), ('news', 'Grand')] # [_start-genre]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>genre_word[-4:]\n",
      "<span class=\"pysrc-output\">[('romance', 'afraid'), ('romance', 'not'), ('romance', \"''\"), ('romance', '.')] # [_end-genre]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We can now use this list of pairs to create a <tt class=\"doctest\"><span class=\"pre\">ConditionalFreqDist</span></tt>, and\n",
      "save it in a variable <tt class=\"doctest\"><span class=\"pre\">cfd</span></tt>.  As usual, we can type the name of the\n",
      "variable to inspect it <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#inspect-cfd\"><span id=\"ref-inspect-cfd\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>, and verify it has two conditions <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#conditions-cfd\"><span id=\"ref-conditions-cfd\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(genre_word)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd <a name=\"inspect-cfd\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-inspect-cfd\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">&lt;ConditionalFreqDist with 2 conditions&gt;</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.conditions()\n",
      "<span class=\"pysrc-output\">['news', 'romance'] # [_conditions-cfd]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Let's access the two conditions, and satisfy ourselves that each is just\n",
      "a frequency distribution:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">print</span>(cfd[<span class=\"pysrc-string\">'news'</span>])\n",
      "<span class=\"pysrc-output\">&lt;FreqDist with 14394 samples and 100554 outcomes&gt;</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">print</span>(cfd[<span class=\"pysrc-string\">'romance'</span>])\n",
      "<span class=\"pysrc-output\">&lt;FreqDist with 8452 samples and 70022 outcomes&gt;</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd[<span class=\"pysrc-string\">'romance'</span>].most_common(20)\n",
      "<span class=\"pysrc-output\">[(',', 3899), ('.', 3736), ('the', 2758), ('and', 1776), ('to', 1502),</span>\n",
      "<span class=\"pysrc-output\">('a', 1335), ('of', 1186), ('``', 1045), (\"''\", 1044), ('was', 993),</span>\n",
      "<span class=\"pysrc-output\">('I', 951), ('in', 875), ('he', 702), ('had', 692), ('?', 690),</span>\n",
      "<span class=\"pysrc-output\">('her', 651), ('that', 583), ('it', 573), ('his', 559), ('she', 496)]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd[<span class=\"pysrc-string\">'romance'</span>][<span class=\"pysrc-string\">'could'</span>]\n",
      "<span class=\"pysrc-output\">193</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"plotting-and-tabulating-distributions\">\n",
      "<h2>2.3&nbsp;&nbsp;&nbsp;Plotting and Tabulating Distributions</h2>\n",
      "<p>Apart from combining two or more frequency distributions, and being easy to initialize,\n",
      "a <tt class=\"doctest\"><span class=\"pre\">ConditionalFreqDist</span></tt> provides some useful methods for tabulation and plotting.</p>\n",
      "<p>The plot in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-inaugural2\">1.1</a> was based on a conditional frequency distribution\n",
      "reproduced in the code below.\n",
      "The condition is either of the words <span class=\"example\">america</span> or <span class=\"example\">citizen</span> <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#america-citizen\"><span id=\"ref-america-citizen\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>,\n",
      "and the counts being plotted are the number of times the word occured in a particular speech.\n",
      "It exploits the fact that the filename for each speech, e.g., <tt class=\"doctest\"><span class=\"pre\">1865-Lincoln.txt</span></tt>\n",
      "contains the year as the first four characters <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#first-four-chars\"><span id=\"ref-first-four-chars\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.\n",
      "This code generates the pair <tt class=\"doctest\"><span class=\"pre\">(<span class=\"pysrc-string\">'america'</span>, <span class=\"pysrc-string\">'1865'</span>)</span></tt> for\n",
      "every instance of a word whose lowercased form starts with <span class=\"example\">america</span>\n",
      "— such as <span class=\"example\">Americans</span> — in the file <tt class=\"doctest\"><span class=\"pre\">1865-Lincoln.txt</span></tt>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> inaugural\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (target, fileid[:4]) <a name=\"first-four-chars\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-first-four-chars\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> inaugural.fileids()\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> inaugural.words(fileid)\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> target <span class=\"pysrc-keyword\">in</span> [<span class=\"pysrc-string\">'america'</span>, <span class=\"pysrc-string\">'citizen'</span>] <a name=\"america-citizen\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-america-citizen\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">if</span> w.lower().startswith(target))</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The plot in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-word-len-dist\">1.2</a> was also based on a conditional frequency distribution,\n",
      "reproduced below.  This time, the condition is the name of the language\n",
      "and the counts being plotted are derived from word lengths <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#lang-len-word\"><span id=\"ref-lang-len-word\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.\n",
      "It exploits the fact that the filename for each language is the language name followed\n",
      "by <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'-Latin1'</span></span></tt> (the character encoding).</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> udhr\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>languages = [<span class=\"pysrc-string\">'Chickasaw'</span>, <span class=\"pysrc-string\">'English'</span>, <span class=\"pysrc-string\">'German_Deutsch'</span>,\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-string\">'Greenlandic_Inuktikut'</span>, <span class=\"pysrc-string\">'Hungarian_Magyar'</span>, <span class=\"pysrc-string\">'Ibibio_Efik'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (lang, len(word)) <a name=\"lang-len-word\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-lang-len-word\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> lang <span class=\"pysrc-keyword\">in</span> languages\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> word <span class=\"pysrc-keyword\">in</span> udhr.words(lang + <span class=\"pysrc-string\">'-Latin1'</span>))</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>In the <tt class=\"doctest\"><span class=\"pre\">plot()</span></tt> and <tt class=\"doctest\"><span class=\"pre\">tabulate()</span></tt> methods, we can\n",
      "optionally specify which conditions to display with a <tt class=\"doctest\"><span class=\"pre\">conditions=</span></tt> parameter.\n",
      "When we omit it, we get all the conditions.  Similarly, we can limit the\n",
      "samples to display with a <tt class=\"doctest\"><span class=\"pre\">samples=</span></tt> parameter.  This makes it possible to\n",
      "load a large quantity of data into a conditional frequency distribution, and then\n",
      "to explore it by plotting or tabulating selected conditions and samples.  It also\n",
      "gives us full control over the order of conditions and samples in any displays.\n",
      "For example, we can tabulate the cumulative frequency data just for two\n",
      "languages, and for words less than 10 characters long, as shown below.\n",
      "We interpret the last cell on the top row to mean that 1,638 words of the\n",
      "English text have 9 or fewer letters.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.tabulate(conditions=[<span class=\"pysrc-string\">'English'</span>, <span class=\"pysrc-string\">'German_Deutsch'</span>],\n",
      "<span class=\"pysrc-more\">... </span>             samples=range(10), cumulative=True)\n",
      "<span class=\"pysrc-output\">                  0    1    2    3    4    5    6    7    8    9</span>\n",
      "<span class=\"pysrc-output\">       English    0  185  525  883  997 1166 1283 1440 1558 1638</span>\n",
      "<span class=\"pysrc-output\">German_Deutsch    0  171  263  614  717  894 1013 1110 1213 1275</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Your Turn:</strong>\n",
      "Working with the news and romance genres from the Brown Corpus,\n",
      "find out which days of the week are most newsworthy, and which are most romantic.\n",
      "Define a variable called <tt class=\"doctest\"><span class=\"pre\">days</span></tt> containing a list of days of the week, i.e.\n",
      "<tt class=\"doctest\"><span class=\"pre\">[<span class=\"pysrc-string\">'Monday'</span>, ...]</span></tt>.  Now tabulate the counts for these words using\n",
      "<tt class=\"doctest\"><span class=\"pre\">cfd.tabulate(samples=days)</span></tt>.  Now try the same thing using <tt class=\"doctest\"><span class=\"pre\">plot</span></tt> in place of <tt class=\"doctest\"><span class=\"pre\">tabulate</span></tt>.\n",
      "You may control the output order of days with the help of an extra parameter:\n",
      "<tt class=\"doctest\"><span class=\"pre\">samples=[<span class=\"pysrc-string\">'Monday'</span>, ...]</span></tt>.</p>\n",
      "</div>\n",
      "<p>You may have noticed that the multi-line expressions we have been\n",
      "using with conditional frequency distributions look like list\n",
      "comprehensions, but without the brackets.  In general,\n",
      "when we use a list comprehension as a parameter to a function,\n",
      "like <tt class=\"doctest\"><span class=\"pre\">set([w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> t])</span></tt>, we are permitted to omit\n",
      "the square brackets and just write: <tt class=\"doctest\"><span class=\"pre\">set(w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> t)</span></tt>.\n",
      "(See the discussion of \"generator expressions\" in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch04.html#sec-sequences\">4.2</a>\n",
      "for more about this.)</p>\n",
      "</div>\n",
      "<div class=\"section\" id=\"generating-random-text-with-bigrams\">\n",
      "<h2>2.4&nbsp;&nbsp;&nbsp;Generating Random Text with Bigrams</h2>\n",
      "<p>We can use a conditional frequency distribution to create a table of\n",
      "bigrams (word pairs). (We introducted bigrams in\n",
      "<a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-simple-statistics\">3</a>.)\n",
      "The <tt class=\"doctest\"><span class=\"pre\">bigrams()</span></tt> function takes a list of\n",
      "words and builds a list of consecutive word pairs.\n",
      "Remember that, in order to see the result and not a cryptic\n",
      "\"generator object\", we need to use the <tt class=\"doctest\"><span class=\"pre\">list()</span></tt> function:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>sent = [<span class=\"pysrc-string\">'In'</span>, <span class=\"pysrc-string\">'the'</span>, <span class=\"pysrc-string\">'beginning'</span>, <span class=\"pysrc-string\">'God'</span>, <span class=\"pysrc-string\">'created'</span>, <span class=\"pysrc-string\">'the'</span>, <span class=\"pysrc-string\">'heaven'</span>,\n",
      "<span class=\"pysrc-more\">... </span>  <span class=\"pysrc-string\">'and'</span>, <span class=\"pysrc-string\">'the'</span>, <span class=\"pysrc-string\">'earth'</span>, <span class=\"pysrc-string\">'.'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>list(nltk.bigrams(sent))\n",
      "<span class=\"pysrc-output\">[('In', 'the'), ('the', 'beginning'), ('beginning', 'God'), ('God', 'created'),</span>\n",
      "<span class=\"pysrc-output\">('created', 'the'), ('the', 'heaven'), ('heaven', 'and'), ('and', 'the'),</span>\n",
      "<span class=\"pysrc-output\">('the', 'earth'), ('earth', '.')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>In <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-random-text\">2.2</a>, we treat each word as a condition, and for each one\n",
      "we effectively create a frequency distribution over the following\n",
      "words.  The function <tt class=\"doctest\"><span class=\"pre\">generate_model()</span></tt> contains a simple loop to\n",
      "generate text. When we call the function, we choose a word (such as\n",
      "<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'living'</span></span></tt>) as our initial context, then once inside the loop, we\n",
      "print the current value of the variable <tt class=\"doctest\"><span class=\"pre\">word</span></tt>, and reset <tt class=\"doctest\"><span class=\"pre\">word</span></tt>\n",
      "to be the most likely token in that context (using <tt class=\"doctest\"><span class=\"pre\">max()</span></tt>); next\n",
      "time through the loop, we use that word as our new context.  As you\n",
      "can see by inspecting the output, this simple approach to text\n",
      "generation tends to get stuck in loops; another method would be to\n",
      "randomly choose the next word from among the available words.</p>\n",
      "<span class=\"target\" id=\"code-random-text\"></span><div class=\"pylisting\">\n",
      "<p></p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"pylisting\" width=\"95%\">\n",
      "<tbody><tr><td class=\"codeblock\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_codeblock_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">generate_model</span>(cfdist, word, num=15):\n",
      "    <span class=\"pysrc-keyword\">for</span> i <span class=\"pysrc-keyword\">in</span> range(num):\n",
      "        <span class=\"pysrc-keyword\">print</span>(word, end=<span class=\"pysrc-string\">' '</span>)\n",
      "        word = cfdist[word].max()\n",
      "\n",
      "text = nltk.corpus.genesis.words(<span class=\"pysrc-string\">'english-kjv.txt'</span>)\n",
      "bigrams = nltk.bigrams(text)\n",
      "cfd = nltk.ConditionalFreqDist(bigrams) <a name=\"bigram-condition\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-bigram-condition\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "<tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd[<span class=\"pysrc-string\">'living'</span>]\n",
      "<span class=\"pysrc-output\">FreqDist({'creature': 7, 'thing': 4, 'substance': 2, ',': 1, '.': 1, 'soul': 1})</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>generate_model(cfd, <span class=\"pysrc-string\">'living'</span>)\n",
      "<span class=\"pysrc-output\">living creature that he said , and the land of the land of the land</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "<tr><td class=\"caption\"><p class=\"caption\"><a class=\"reference external\" href=\"https://www.nltk.org/book/pylisting/code_random_text.py\" type=\"text/x-python\"><span class=\"caption-label\">Example 2.2 (code_random_text.py)</span></a>: <span class=\"caption-label\">Figure 2.2</span>: Generating Random Text: this program obtains all bigrams\n",
      "from the text of the book of Genesis, then constructs a\n",
      "conditional frequency distribution to record which\n",
      "words are most likely to follow a given word; e.g., after\n",
      "the word <span class=\"example\">living</span>, the most likely word is\n",
      "<span class=\"example\">creature</span>; the <tt class=\"doctest\"><span class=\"pre\">generate_model()</span></tt> function uses this\n",
      "data, and a seed word, to generate random text.</p></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Conditional frequency distributions are a useful data structure for many NLP tasks.\n",
      "Their commonly-used methods are summarized in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#tab-conditionalfreqdist\">2.1</a>.</p>\n",
      "<span class=\"target\" id=\"tab-conditionalfreqdist\"></span><p class=\"caption\"><span class=\"caption-label\">Table 2.1</span>: </p><p>NLTK's Conditional Frequency Distributions: commonly-used methods and idioms for defining,\n",
      "accessing, and visualizing a conditional frequency distribution of counters.</p><p></p><table border=\"1\" class=\"docutils\" id=\"tab-conditionalfreqdist\">\n",
      "<colgroup>\n",
      "<col width=\"36%\">\n",
      "<col width=\"64%\">\n",
      "</colgroup>\n",
      "<thead valign=\"bottom\">\n",
      "<tr><th class=\"head\">Example</th>\n",
      "<th class=\"head\">Description</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist = ConditionalFreqDist(pairs)</span></tt></td>\n",
      "<td>create a conditional frequency distribution from a list of pairs</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist.conditions()</span></tt></td>\n",
      "<td>the conditions</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist[condition]</span></tt></td>\n",
      "<td>the frequency distribution for this condition</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist[condition][sample]</span></tt></td>\n",
      "<td>frequency for the given sample for this condition</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist.tabulate()</span></tt></td>\n",
      "<td>tabulate the conditional frequency distribution</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist.tabulate(samples, conditions)</span></tt></td>\n",
      "<td>tabulation limited to the specified samples and conditions</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist.plot()</span></tt></td>\n",
      "<td>graphical plot of the conditional frequency distribution</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist.plot(samples, conditions)</span></tt></td>\n",
      "<td>graphical plot limited to the specified samples and conditions</td>\n",
      "</tr>\n",
      "<tr><td><tt class=\"doctest\"><span class=\"pre\">cfdist1 &lt; cfdist2</span></tt></td>\n",
      "<td>test if samples in <tt class=\"doctest\"><span class=\"pre\">cfdist1</span></tt> occur less frequently than in <tt class=\"doctest\"><span class=\"pre\">cfdist2</span></tt></td>\n",
      "</tr>\n",
      "</tbody>\n",
      "\n",
      "\n",
      "</table>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"more-python-reusing-code\">\n",
      "<span id=\"sec-reusing-code\"></span><h1>3&nbsp;&nbsp;&nbsp;More Python: Reusing Code</h1>\n",
      "<p>By this time you've probably typed and retyped a lot of code in the Python\n",
      "interactive interpreter.  If you mess up when retyping a complex example you have\n",
      "to enter it again.  Using the arrow keys to access and modify previous commands is helpful but only goes so\n",
      "far.  In this section we see two important ways to reuse code: text editors and Python functions.</p>\n",
      "<div class=\"section\" id=\"creating-programs-with-a-text-editor\">\n",
      "<h2>3.1&nbsp;&nbsp;&nbsp;Creating Programs with a Text Editor</h2>\n",
      "<p>The Python interactive interpreter performs your instructions as soon as you type\n",
      "them.  Often, it is better to compose a multi-line program using a text editor,\n",
      "then ask Python to run the whole program at once.  Using IDLE, you can do\n",
      "this by going to the <tt class=\"doctest\"><span class=\"pre\">File</span></tt> menu and opening a new window.  Try this now, and\n",
      "enter the following one-line program:</p>\n",
      "<pre class=\"literal-block\">print('Monty Python')\n",
      "</pre>\n",
      "<p>Save this program in a file called <tt class=\"doctest\"><span class=\"pre\">monty.py</span></tt>, then\n",
      "go to the <tt class=\"doctest\"><span class=\"pre\">Run</span></tt> menu, and select the command <tt class=\"doctest\"><span class=\"pre\">Run Module</span></tt>.\n",
      "(We'll learn what modules are shortly.)\n",
      "The result in the main IDLE window should look like this:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>================================ RESTART ================================\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt;</span>\n",
      "<span class=\"pysrc-output\">Monty Python</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt;</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>You can also type <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">from</span> monty <span class=\"pysrc-keyword\">import</span> *</span></tt> and it will do the same thing.</p>\n",
      "<p>From now on, you have a choice of using the interactive interpreter or a\n",
      "text editor to create your programs.  It is often convenient to test your ideas\n",
      "using the interpreter, revising a line of code until it does what you expect.\n",
      "Once you're ready, you can paste the code\n",
      "(minus any <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-prompt\">&gt;&gt;&gt;</span></span></tt> or <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-more\">...</span></span></tt> prompts) into the text editor,\n",
      "continue to expand it, and finally save the program\n",
      "in a file so that you don't have to type it in again later.\n",
      "Give the file a short but descriptive name, using all lowercase letters and separating\n",
      "words with underscore, and using the <tt class=\"doctest\"><span class=\"pre\">.py</span></tt> filename extension, e.g., <tt class=\"doctest\"><span class=\"pre\">monty_python.py</span></tt>.</p>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Important:</strong>\n",
      "Our inline code examples include the <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-prompt\">&gt;&gt;&gt;</span></span></tt> and <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-more\">...</span></span></tt> prompts\n",
      "as if we are interacting directly with the interpreter.  As they get more complicated,\n",
      "you should instead type them into the editor, without the prompts, and run them\n",
      "from the editor as shown above.  When we provide longer programs in this book,\n",
      "we will leave out the prompts to remind you to type them into a file rather\n",
      "than using the interpreter.  You can see this already in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-random-text\">2.2</a> above.\n",
      "Note that it still includes a couple of lines with the Python prompt;\n",
      "this is the interactive part of the task where you inspect some data and invoke a function.\n",
      "Remember that all code samples like <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-random-text\">2.2</a> are downloadable\n",
      "from <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/</span></tt>.</p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"functions\">\n",
      "<h2>3.2&nbsp;&nbsp;&nbsp;Functions</h2>\n",
      "<p>Suppose that you work on analyzing text that involves different forms\n",
      "of the same word, and that part of your program needs to work out\n",
      "the plural form of a given singular noun.  Suppose it needs to do this\n",
      "work in two places, once when it is processing some texts, and again\n",
      "when it is processing user input.</p>\n",
      "<p>Rather than repeating the same code several times over, it is more\n",
      "efficient and reliable to localize this work inside a <a name=\"function_index_term\"><span class=\"termdef\">function</span>.\n",
      "A function is just a named block of code that performs some well-defined\n",
      "task, as we saw in </a><a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>.\n",
      "A function is usually defined to take some inputs, using special variables known as <a name=\"parameters_index_term\"><span class=\"termdef\">parameters</span>,\n",
      "and it may produce a result, also known as a </a><a name=\"return_value_index_term\"><span class=\"termdef\">return value</span>.\n",
      "We define a function using the keyword <tt class=\"doctest\"><span class=\"pre\">def</span></tt> followed by the\n",
      "function name and any input parameters, followed by the body of the\n",
      "function.  Here's the function we saw in </a><a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>\n",
      "(including the <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span></span></tt> statement that is needed for Python 2, in order to make division behave as expected):</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> __future__ <span class=\"pysrc-keyword\">import</span> division\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">lexical_diversity</span>(text):\n",
      "<span class=\"pysrc-more\">... </span>    return len(text) / len(set(text))</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We use the keyword <tt class=\"doctest\"><span class=\"pre\">return</span></tt> to indicate the value that is\n",
      "produced as output by the function.  In the above example,\n",
      "all the work of the function is done in the <tt class=\"doctest\"><span class=\"pre\">return</span></tt> statement.\n",
      "Here's an equivalent definition which does the same work\n",
      "using multiple lines of code.  We'll change the parameter name\n",
      "from <tt class=\"doctest\"><span class=\"pre\">text</span></tt> to <tt class=\"doctest\"><span class=\"pre\">my_text_data</span></tt> to remind you that this is an arbitrary choice:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">lexical_diversity</span>(my_text_data):\n",
      "<span class=\"pysrc-more\">... </span>    word_count = len(my_text_data)\n",
      "<span class=\"pysrc-more\">... </span>    vocab_size = len(set(my_text_data))\n",
      "<span class=\"pysrc-more\">... </span>    diversity_score = vocab_size / word_count\n",
      "<span class=\"pysrc-more\">... </span>    return diversity_score</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Notice that we've created some new variables inside the body of the function.\n",
      "These are <a name=\"local_variables_index_term\"><span class=\"termdef\">local variables</span> and are not accessible outside the function.\n",
      "So now we have defined a function with the name <tt class=\"doctest\"><span class=\"pre\">lexical_diversity</span></tt>. But just\n",
      "defining it won't produce any output!\n",
      "Functions do nothing until they are \"called\" (or \"invoked\"):</a></p><a name=\"local_variables_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> genesis\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>kjv = genesis.words(<span class=\"pysrc-string\">'english-kjv.txt'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>lexical_diversity(kjv)\n",
      "<span class=\"pysrc-output\">0.06230453042623537</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"local_variables_index_term\">Let's return to our earlier scenario, and actually define a simple\n",
      "function to work out English plurals.  The function <tt class=\"doctest\"><span class=\"pre\">plural()</span></tt> in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-plural\">3.1</a>\n",
      "takes a singular noun and generates a plural form, though it is not always\n",
      "correct.  (We'll discuss functions at greater length in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch04.html#sec-functions\">4.4</a>.)</p>\n",
      "<span class=\"target\" id=\"code-plural\"></span><div class=\"pylisting\">\n",
      "<p></p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"pylisting\" width=\"95%\">\n",
      "<tbody><tr><td class=\"codeblock\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_codeblock_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">plural</span>(word):\n",
      "    <span class=\"pysrc-keyword\">if</span> word.endswith(<span class=\"pysrc-string\">'y'</span>):\n",
      "        return word[:-1] + <span class=\"pysrc-string\">'ies'</span>\n",
      "    <span class=\"pysrc-keyword\">elif</span> word[-1] <span class=\"pysrc-keyword\">in</span> <span class=\"pysrc-string\">'sx'</span> <span class=\"pysrc-keyword\">or</span> word[-2:] <span class=\"pysrc-keyword\">in</span> [<span class=\"pysrc-string\">'sh'</span>, <span class=\"pysrc-string\">'ch'</span>]:\n",
      "        return word + <span class=\"pysrc-string\">'es'</span>\n",
      "    <span class=\"pysrc-keyword\">elif</span> word.endswith(<span class=\"pysrc-string\">'an'</span>):\n",
      "        return word[:-2] + <span class=\"pysrc-string\">'en'</span>\n",
      "    <span class=\"pysrc-keyword\">else</span>:\n",
      "        return word + <span class=\"pysrc-string\">'s'</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "<tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>plural(<span class=\"pysrc-string\">'fairy'</span>)\n",
      "<span class=\"pysrc-output\">'fairies'</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>plural(<span class=\"pysrc-string\">'woman'</span>)\n",
      "<span class=\"pysrc-output\">'women'</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "<tr><td class=\"caption\"><p class=\"caption\"><a class=\"reference external\" href=\"https://www.nltk.org/book/pylisting/code_plural.py\" type=\"text/x-python\"><span class=\"caption-label\">Example 3.1 (code_plural.py)</span></a>: <span class=\"caption-label\">Figure 3.1</span>: A Python Function: this function tries to work out the\n",
      "plural form of any English noun; the keyword <tt class=\"doctest\"><span class=\"pre\">def</span></tt> (define)\n",
      "is followed by the function name, then a parameter inside\n",
      "parentheses, and a colon; the body of the function is the\n",
      "indented block of code; it tries to recognize patterns\n",
      "within the word and process the word accordingly; e.g., if the\n",
      "word ends with <span class=\"example\">y</span>, delete the <span class=\"example\">y</span> and add <span class=\"example\">ies</span>.</p></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The <tt class=\"doctest\"><span class=\"pre\">endswith()</span></tt> function is always associated with a string object\n",
      "(e.g., <tt class=\"doctest\"><span class=\"pre\">word</span></tt> in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-plural\">3.1</a>).  To call such functions, we give\n",
      "the name of the object, a period, and then the name of the function.\n",
      "These functions are usually known as <a name=\"methods_index_term\"><span class=\"termdef\">methods</span>.</a></p><a name=\"methods_index_term\">\n",
      "</a></div><a name=\"methods_index_term\">\n",
      "</a><div class=\"section\" id=\"modules\"><a name=\"methods_index_term\">\n",
      "<h2>3.3&nbsp;&nbsp;&nbsp;Modules</h2>\n",
      "<p>Over time you will find that you create a variety of useful little text processing functions,\n",
      "and you end up copying them from old programs to new ones.  Which file contains the\n",
      "latest version of the function you want to use?\n",
      "It makes life a lot easier if you can collect your work into a single place, and\n",
      "access previously defined functions without making copies.</p>\n",
      "<p>To do this, save your function(s) in a file called (say) <tt class=\"doctest\"><span class=\"pre\">text_proc.py</span></tt>.\n",
      "Now, you can access your work simply by importing it from the file:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> text_proc <span class=\"pysrc-keyword\">import</span> plural\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>plural(<span class=\"pysrc-string\">'wish'</span>)\n",
      "<span class=\"pysrc-output\">wishes</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>plural(<span class=\"pysrc-string\">'fan'</span>)\n",
      "<span class=\"pysrc-output\">fen</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Our plural function obviously has an error, since the plural of\n",
      "<span class=\"example\">fan</span> is <span class=\"example\">fans</span>.\n",
      "Instead of typing in a new version of the function, we can\n",
      "simply edit the existing one.  Thus, at every\n",
      "stage, there is only one version of our plural function, and no confusion about\n",
      "which one is being used.</p>\n",
      "</a><p><a name=\"methods_index_term\">A collection of variable and function definitions in a file is called a Python\n",
      "</a><a name=\"module_index_term\"><span class=\"termdef\">module</span>.  A collection of related modules is called a </a><a name=\"package_index_term\"><span class=\"termdef\">package</span>.\n",
      "NLTK's code for processing the Brown Corpus is an example of a module,\n",
      "and its collection of code for processing all the different corpora is\n",
      "an example of a package.  NLTK itself is a set of packages, sometimes\n",
      "called a </a><a name=\"library_index_term\"><span class=\"termdef\">library</span>.</a></p><a name=\"library_index_term\">\n",
      "<div class=\"admonition caution\">\n",
      "<p class=\"first admonition-title\">Caution!</p>\n",
      "<p class=\"last\">If you are creating a file to contain some of your Python\n",
      "code, do <em>not</em> name your file <tt class=\"doctest\"><span class=\"pre\">nltk.py</span></tt>: it may get imported in\n",
      "place of the \"real\" NLTK package.  When it imports modules, Python\n",
      "first looks in the current directory (folder).</p>\n",
      "</div>\n",
      "</a></div><a name=\"library_index_term\">\n",
      "</a></div><a name=\"library_index_term\">\n",
      "</a><div class=\"section\" id=\"lexical-resources\"><a name=\"library_index_term\">\n",
      "<span id=\"sec-lexical-resources\"></span><h1>4&nbsp;&nbsp;&nbsp;Lexical Resources</h1>\n",
      "</a><p><a name=\"library_index_term\">A lexicon, or lexical resource, is a collection of words and/or phrases along\n",
      "with associated information such as part of speech and sense definitions.\n",
      "Lexical resources are secondary to texts, and are usually created and enriched with the help\n",
      "of texts.  For example, if we have defined a text <tt class=\"doctest\"><span class=\"pre\">my_text</span></tt>, then\n",
      "<tt class=\"doctest\"><span class=\"pre\">vocab = sorted(set(my_text))</span></tt> builds the vocabulary of <tt class=\"doctest\"><span class=\"pre\">my_text</span></tt>,\n",
      "while <tt class=\"doctest\"><span class=\"pre\">word_freq = FreqDist(my_text)</span></tt> counts the frequency of each word in the text.  Both\n",
      "of <tt class=\"doctest\"><span class=\"pre\">vocab</span></tt> and <tt class=\"doctest\"><span class=\"pre\">word_freq</span></tt> are simple lexical resources.  Similarly, a concordance\n",
      "like the one we saw in </a><a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#sec-computing-with-language-texts-and-words\">1</a>\n",
      "gives us information about word usage that might help in the preparation of\n",
      "a dictionary.  Standard terminology for lexicons is illustrated in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-lexicon\">4.1</a>.\n",
      "A <a name=\"lexical_entry_index_term\"><span class=\"termdef\">lexical entry</span> consists of a </a><a name=\"headword_index_term\"><span class=\"termdef\">headword</span> (also known as a </a><a name=\"lemma_index_term\"><span class=\"termdef\">lemma</span>)\n",
      "along with additional information such as the part of speech and the sense\n",
      "definition.  Two distinct words having the same spelling are called </a><a name=\"homonyms_index_term\"><span class=\"termdef\">homonyms</span>.</a></p><a name=\"homonyms_index_term\">\n",
      "<span class=\"target\" id=\"fig-lexicon\"></span><div class=\"figure\" id=\"fig-lexicon\">\n",
      "<img alt=\"../images/lexicon.png\" src=\"./kadai3_files/lexicon.png\" style=\"width: 504.0px; height: 223.20000000000002px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 4.1</span>: Lexicon Terminology: lexical entries for two lemmas\n",
      "having the same spelling (homonyms), providing part of speech\n",
      "and gloss information.</p>\n",
      "</div>\n",
      "<p>The simplest kind of lexicon is nothing more than a sorted list of words.\n",
      "Sophisticated lexicons include complex structure within and across\n",
      "the individual entries.  In this section we'll look at some lexical resources\n",
      "included with NLTK.</p>\n",
      "</a><div class=\"section\" id=\"wordlist-corpora\"><a name=\"homonyms_index_term\">\n",
      "<h2>4.1&nbsp;&nbsp;&nbsp;Wordlist Corpora</h2>\n",
      "<!-- XXX There's a useful opportunity here to link back to the discussion of what words\n",
      "characterize a text found in ch01. -->\n",
      "</a><p><a name=\"homonyms_index_term\">NLTK includes some corpora that are nothing more than wordlists.\n",
      "The Words Corpus is the <tt class=\"doctest\"><span class=\"pre\">/usr/share/dict/words</span></tt> file from Unix, used by\n",
      "some spell checkers.  We can use it to find unusual or mis-spelt\n",
      "words in a text corpus, as shown in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-unusual\">4.2</a>.</p>\n",
      "<span class=\"target\" id=\"code-unusual\"></span><div class=\"pylisting\">\n",
      "<p></p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"pylisting\" width=\"95%\">\n",
      "<tbody><tr><td class=\"codeblock\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_codeblock_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">unusual_words</span>(text):\n",
      "    text_vocab = set(w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> text <span class=\"pysrc-keyword\">if</span> w.isalpha())\n",
      "    english_vocab = set(w.lower() <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> nltk.corpus.words.words())\n",
      "    unusual = text_vocab - english_vocab\n",
      "    return sorted(unusual)\n",
      "\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>unusual_words(nltk.corpus.gutenberg.words(<span class=\"pysrc-string\">'austen-sense.txt'</span>))\n",
      "[<span class=\"pysrc-string\">'abbeyland'</span>, <span class=\"pysrc-string\">'abhorred'</span>, <span class=\"pysrc-string\">'abilities'</span>, <span class=\"pysrc-string\">'abounded'</span>, <span class=\"pysrc-string\">'abridgement'</span>, <span class=\"pysrc-string\">'abused'</span>, <span class=\"pysrc-string\">'abuses'</span>,\n",
      "<span class=\"pysrc-string\">'accents'</span>, <span class=\"pysrc-string\">'accepting'</span>, <span class=\"pysrc-string\">'accommodations'</span>, <span class=\"pysrc-string\">'accompanied'</span>, <span class=\"pysrc-string\">'accounted'</span>, <span class=\"pysrc-string\">'accounts'</span>,\n",
      "<span class=\"pysrc-string\">'accustomary'</span>, <span class=\"pysrc-string\">'aches'</span>, <span class=\"pysrc-string\">'acknowledging'</span>, <span class=\"pysrc-string\">'acknowledgment'</span>, <span class=\"pysrc-string\">'acknowledgments'</span>, ...]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>unusual_words(nltk.corpus.nps_chat.words())\n",
      "[<span class=\"pysrc-string\">'aaaaaaaaaaaaaaaaa'</span>, <span class=\"pysrc-string\">'aaahhhh'</span>, <span class=\"pysrc-string\">'abortions'</span>, <span class=\"pysrc-string\">'abou'</span>, <span class=\"pysrc-string\">'abourted'</span>, <span class=\"pysrc-string\">'abs'</span>, <span class=\"pysrc-string\">'ack'</span>,\n",
      "<span class=\"pysrc-string\">'acros'</span>, <span class=\"pysrc-string\">'actualy'</span>, <span class=\"pysrc-string\">'adams'</span>, <span class=\"pysrc-string\">'adds'</span>, <span class=\"pysrc-string\">'adduser'</span>, <span class=\"pysrc-string\">'adjusts'</span>, <span class=\"pysrc-string\">'adoted'</span>, <span class=\"pysrc-string\">'adreniline'</span>,\n",
      "<span class=\"pysrc-string\">'ads'</span>, <span class=\"pysrc-string\">'adults'</span>, <span class=\"pysrc-string\">'afe'</span>, <span class=\"pysrc-string\">'affairs'</span>, <span class=\"pysrc-string\">'affari'</span>, <span class=\"pysrc-string\">'affects'</span>, <span class=\"pysrc-string\">'afk'</span>, <span class=\"pysrc-string\">'agaibn'</span>, <span class=\"pysrc-string\">'ages'</span>, ...]</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "<tr><td class=\"caption\"><p class=\"caption\"><a class=\"reference external\" href=\"https://www.nltk.org/book/pylisting/code_unusual.py\" type=\"text/x-python\"><span class=\"caption-label\">Example 4.2 (code_unusual.py)</span></a>: <span class=\"caption-label\">Figure 4.2</span>: Filtering a Text: this program computes the vocabulary of a text,\n",
      "then removes all items that occur in an existing wordlist,\n",
      "leaving just the uncommon or mis-spelt words.</p></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>There is also a corpus of <a name=\"stopwords_index_term\"><span class=\"termdef\">stopwords</span>, that is, high-frequency\n",
      "words like <span class=\"example\">the</span>, <span class=\"example\">to</span> and <span class=\"example\">also</span> that we sometimes\n",
      "want to filter out of a document before further processing. Stopwords\n",
      "usually have little lexical content, and their presence in a text fails\n",
      "to distinguish it from other texts.</a></p><a name=\"stopwords_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> stopwords\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>stopwords.words(<span class=\"pysrc-string\">'english'</span>)\n",
      "<span class=\"pysrc-output\">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',</span>\n",
      "<span class=\"pysrc-output\">'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',</span>\n",
      "<span class=\"pysrc-output\">'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',</span>\n",
      "<span class=\"pysrc-output\">'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',</span>\n",
      "<span class=\"pysrc-output\">'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',</span>\n",
      "<span class=\"pysrc-output\">'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',</span>\n",
      "<span class=\"pysrc-output\">'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',</span>\n",
      "<span class=\"pysrc-output\">'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',</span>\n",
      "<span class=\"pysrc-output\">'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',</span>\n",
      "<span class=\"pysrc-output\">'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',</span>\n",
      "<span class=\"pysrc-output\">'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',</span>\n",
      "<span class=\"pysrc-output\">'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Let's define a function to compute what fraction of words in a text are <em>not</em> in the\n",
      "stopwords list:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">content_fraction</span>(text):\n",
      "<span class=\"pysrc-more\">... </span>    stopwords = nltk.corpus.stopwords.words(<span class=\"pysrc-string\">'english'</span>)\n",
      "<span class=\"pysrc-more\">... </span>    content = [w <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> text <span class=\"pysrc-keyword\">if</span> w.lower() <span class=\"pysrc-keyword\">not</span> <span class=\"pysrc-keyword\">in</span> stopwords]\n",
      "<span class=\"pysrc-more\">... </span>    return len(content) / len(text)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>content_fraction(nltk.corpus.reuters.words())\n",
      "<span class=\"pysrc-output\">0.7364374824583169</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Thus, with the help of stopwords we filter out over a quarter of the words of the text.\n",
      "Notice that we've combined two different kinds of corpus here, using a lexical\n",
      "resource to filter the content of a text corpus.</p>\n",
      "<span class=\"target\" id=\"fig-target\"></span><div class=\"figure\" id=\"fig-target\">\n",
      "<img alt=\"../images/target.png\" src=\"./kadai3_files/target.png\" style=\"width: 652.5px; height: 133.79999999999998px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 4.3</span>: A Word Puzzle: a grid of randomly chosen letters with rules for\n",
      "creating words out of the letters; this puzzle is known as \"Target.\"</p>\n",
      "</div>\n",
      "</a><p><a name=\"stopwords_index_term\">A wordlist is useful for solving word puzzles, such as the one in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-target\">4.3</a>.\n",
      "Our program iterates through every word and, for each one, checks whether it meets\n",
      "the conditions.  It is easy to check obligatory letter <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#obligatory-letter\"><span id=\"ref-obligatory-letter\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>\n",
      "and length constraints <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#length-constraint\"><span id=\"ref-length-constraint\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a> (and we'll\n",
      "only look for words with six or more letters here).\n",
      "It is trickier to check that candidate solutions only use combinations of the\n",
      "supplied letters, especially since some of the supplied letters\n",
      "appear twice (here, the letter <span class=\"example\">v</span>).\n",
      "The <tt class=\"doctest\"><span class=\"pre\">FreqDist</span></tt> comparison method <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#freqdist-compare\"><span id=\"ref-freqdist-compare\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></span></a> permits us to check that\n",
      "the frequency of each <em>letter</em> in the candidate word is less than or equal\n",
      "to the frequency of the corresponding letter in the puzzle.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>puzzle_letters = nltk.FreqDist(<span class=\"pysrc-string\">'egivrvonl'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>obligatory = <span class=\"pysrc-string\">'r'</span>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wordlist = nltk.corpus.words.words()\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[w <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> wordlist <span class=\"pysrc-keyword\">if</span> len(w) &gt;= 6 <a name=\"length-constraint\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-length-constraint\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>                     <span class=\"pysrc-keyword\">and</span> obligatory <span class=\"pysrc-keyword\">in</span> w <a name=\"obligatory-letter\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-obligatory-letter\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>                     <span class=\"pysrc-keyword\">and</span> nltk.FreqDist(w) &lt;= puzzle_letters] <a name=\"freqdist-compare\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-freqdist-compare\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">['glover', 'gorlin', 'govern', 'grovel', 'ignore', 'involver', 'lienor',</span>\n",
      "<span class=\"pysrc-output\">'linger', 'longer', 'lovering', 'noiler', 'overling', 'region', 'renvoi',</span>\n",
      "<span class=\"pysrc-output\">'revolving', 'ringle', 'roving', 'violer', 'virole']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>One more wordlist corpus is the Names corpus, containing 8,000 first names categorized by gender.\n",
      "The male and female names are stored in separate files.  Let's find names which appear\n",
      "in both files, i.e. names that are ambiguous for gender:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>names = nltk.corpus.names\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>names.fileids()\n",
      "<span class=\"pysrc-output\">['female.txt', 'male.txt']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>male_names = names.words(<span class=\"pysrc-string\">'male.txt'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>female_names = names.words(<span class=\"pysrc-string\">'female.txt'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[w <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> male_names <span class=\"pysrc-keyword\">if</span> w <span class=\"pysrc-keyword\">in</span> female_names]\n",
      "<span class=\"pysrc-output\">['Abbey', 'Abbie', 'Abby', 'Addie', 'Adrian', 'Adrien', 'Ajay', 'Alex', 'Alexis',</span>\n",
      "<span class=\"pysrc-output\">'Alfie', 'Ali', 'Alix', 'Allie', 'Allyn', 'Andie', 'Andrea', 'Andy', 'Angel',</span>\n",
      "<span class=\"pysrc-output\">'Angie', 'Ariel', 'Ashley', 'Aubrey', 'Augustine', 'Austin', 'Averil', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>It is well known that names ending in the letter <span class=\"example\">a</span> are almost always female.\n",
      "We can see this and some other patterns in the graph in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-cfd-gender\">4.4</a>,\n",
      "produced by the following code.  Remember that <tt class=\"doctest\"><span class=\"pre\">name[-1]</span></tt> is the last letter\n",
      "of <tt class=\"doctest\"><span class=\"pre\">name</span></tt>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(\n",
      "<span class=\"pysrc-more\">... </span>          (fileid, name[-1])\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> fileid <span class=\"pysrc-keyword\">in</span> names.fileids()\n",
      "<span class=\"pysrc-more\">... </span>          <span class=\"pysrc-keyword\">for</span> name <span class=\"pysrc-keyword\">in</span> names.words(fileid))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd.plot()</pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<span class=\"target\" id=\"fig-cfd-gender\"></span><div class=\"figure\" id=\"fig-cfd-gender\">\n",
      "<img alt=\"../images/cfd-gender.png\" src=\"./kadai3_files/cfd-gender.png\" style=\"width: 613.0px; height: 463.0px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 4.4</span>: Conditional Frequency Distribution: this plot shows the number of female and male names\n",
      "ending with each letter of the alphabet; most names ending with <span class=\"example\">a</span>, <span class=\"example\">e</span> or <span class=\"example\">i</span>\n",
      "are female; names ending in <span class=\"example\">h</span> and <span class=\"example\">l</span> are equally likely to be male or female;\n",
      "names ending in <span class=\"example\">k</span>, <span class=\"example\">o</span>, <span class=\"example\">r</span>, <span class=\"example\">s</span>, and <span class=\"example\">t</span> are likely to be male.</p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"a-pronouncing-dictionary\">\n",
      "<h2>4.2&nbsp;&nbsp;&nbsp;A Pronouncing Dictionary</h2>\n",
      "<p>A slightly richer kind of lexical resource is a table (or spreadsheet), containing a word\n",
      "plus some properties in each row.  NLTK includes the CMU Pronouncing\n",
      "Dictionary for US English, which was designed for\n",
      "use by speech synthesizers.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>entries = nltk.corpus.cmudict.entries()\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>len(entries)\n",
      "<span class=\"pysrc-output\">133737</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> entry <span class=\"pysrc-keyword\">in</span> entries[42371:42379]:\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(entry)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">('fir', ['F', 'ER1'])</span>\n",
      "<span class=\"pysrc-output\">('fire', ['F', 'AY1', 'ER0'])</span>\n",
      "<span class=\"pysrc-output\">('fire', ['F', 'AY1', 'R'])</span>\n",
      "<span class=\"pysrc-output\">('firearm', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M'])</span>\n",
      "<span class=\"pysrc-output\">('firearm', ['F', 'AY1', 'R', 'AA2', 'R', 'M'])</span>\n",
      "<span class=\"pysrc-output\">('firearms', ['F', 'AY1', 'ER0', 'AA2', 'R', 'M', 'Z'])</span>\n",
      "<span class=\"pysrc-output\">('firearms', ['F', 'AY1', 'R', 'AA2', 'R', 'M', 'Z'])</span>\n",
      "<span class=\"pysrc-output\">('fireball', ['F', 'AY1', 'ER0', 'B', 'AO2', 'L'])</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>For each word, this lexicon provides a list of phonetic\n",
      "codes — distinct labels for each contrastive sound —\n",
      "known as <span class=\"example\">phones</span>.  Observe that <span class=\"example\">fire</span> has two pronunciations\n",
      "(in US English):\n",
      "the one-syllable <tt class=\"doctest\"><span class=\"pre\">F AY1 R</span></tt>, and the two-syllable <tt class=\"doctest\"><span class=\"pre\">F AY1 ER0</span></tt>.\n",
      "The symbols in the CMU Pronouncing Dictionary are from the <em>Arpabet</em>,\n",
      "described in more detail at <tt class=\"doctest\"><span class=\"pre\">http://en.wikipedia.org/wiki/Arpabet</span></tt></p>\n",
      "<!-- XXX Hmm - - would it be better to first explain tuple assignment outside the\n",
      "context of a for loop?  (not sure how to fix this; can't use the word \"tuple\" yet) -->\n",
      "<p>Each entry consists of two parts, and we can\n",
      "process these individually using a more complex version of the <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">for</span></span></tt> statement.\n",
      "Instead of writing <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">for</span> entry <span class=\"pysrc-keyword\">in</span> entries:</span></tt>, we replace\n",
      "<tt class=\"doctest\"><span class=\"pre\">entry</span></tt> with <em>two</em> variable names, <tt class=\"doctest\"><span class=\"pre\">word, pron</span></tt> <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#word-pron\"><span id=\"ref-word-pron\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.\n",
      "Now, each time through the loop, <tt class=\"doctest\"><span class=\"pre\">word</span></tt> is assigned the first part of the\n",
      "entry, and <tt class=\"doctest\"><span class=\"pre\">pron</span></tt> is assigned the second part of the entry:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> word, pron <span class=\"pysrc-keyword\">in</span> entries: <a name=\"word-pron\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-word-pron\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">if</span> len(pron) == 3: <a name=\"len-pron-three\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-len-pron-three\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>        ph1, ph2, ph3 = pron <a name=\"tuple-assignment\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-tuple-assignment\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>        <span class=\"pysrc-keyword\">if</span> ph1 == <span class=\"pysrc-string\">'P'</span> <span class=\"pysrc-keyword\">and</span> ph3 == <span class=\"pysrc-string\">'T'</span>:\n",
      "<span class=\"pysrc-more\">... </span>            <span class=\"pysrc-keyword\">print</span>(word, ph2, end=<span class=\"pysrc-string\">' '</span>)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">pait EY1 pat AE1 pate EY1 patt AE1 peart ER1 peat IY1 peet IY1 peete IY1 pert ER1</span>\n",
      "<span class=\"pysrc-output\">pet EH1 pete IY1 pett EH1 piet IY1 piette IY1 pit IH1 pitt IH1 pot AA1 pote OW1</span>\n",
      "<span class=\"pysrc-output\">pott AA1 pout AW1 puett UW1 purt ER1 put UH1 putt AH1</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The above program scans the lexicon looking for entries whose pronunciation consists of\n",
      "three phones <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#len-pron-three\"><span id=\"ref-len-pron-three\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>.  If the condition is true, it assigns the contents\n",
      "of <tt class=\"doctest\"><span class=\"pre\">pron</span></tt> to three new variables <tt class=\"doctest\"><span class=\"pre\">ph1</span></tt>, <tt class=\"doctest\"><span class=\"pre\">ph2</span></tt> and <tt class=\"doctest\"><span class=\"pre\">ph3</span></tt>.  Notice the unusual\n",
      "form of the statement which does that work <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#tuple-assignment\"><span id=\"ref-tuple-assignment\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></span></a>.</p>\n",
      "<p>Here's another example of the same <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">for</span></span></tt> statement, this time used inside a list\n",
      "comprehension.  This program finds all words whose pronunciation ends with a syllable\n",
      "sounding like <span class=\"example\">nicks</span>.  You could use this method to find rhyming words.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>syllable = [<span class=\"pysrc-string\">'N'</span>, <span class=\"pysrc-string\">'IH0'</span>, <span class=\"pysrc-string\">'K'</span>, <span class=\"pysrc-string\">'S'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[word <span class=\"pysrc-keyword\">for</span> word, pron <span class=\"pysrc-keyword\">in</span> entries <span class=\"pysrc-keyword\">if</span> pron[-4:] == syllable]\n",
      "<span class=\"pysrc-output\">[\"atlantic's\", 'audiotronics', 'avionics', 'beatniks', 'calisthenics', 'centronics',</span>\n",
      "<span class=\"pysrc-output\">'chamonix', 'chetniks', \"clinic's\", 'clinics', 'conics', 'conics', 'cryogenics',</span>\n",
      "<span class=\"pysrc-output\">'cynics', 'diasonics', \"dominic's\", 'ebonics', 'electronics', \"electronics'\", ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Notice that the one pronunciation is spelt in several ways: <span class=\"example\">nics</span>, <span class=\"example\">niks</span>, <span class=\"example\">nix</span>,\n",
      "even <span class=\"example\">ntic's</span> with a silent <span class=\"example\">t</span>, for the word <span class=\"example\">atlantic's</span>.  Let's look for some other\n",
      "mismatches between pronunciation and writing.  Can you summarize the purpose of\n",
      "the following examples and explain how they work?</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[w <span class=\"pysrc-keyword\">for</span> w, pron <span class=\"pysrc-keyword\">in</span> entries <span class=\"pysrc-keyword\">if</span> pron[-1] == <span class=\"pysrc-string\">'M'</span> <span class=\"pysrc-keyword\">and</span> w[-1] == <span class=\"pysrc-string\">'n'</span>]\n",
      "<span class=\"pysrc-output\">['autumn', 'column', 'condemn', 'damn', 'goddamn', 'hymn', 'solemn']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>sorted(set(w[:2] <span class=\"pysrc-keyword\">for</span> w, pron <span class=\"pysrc-keyword\">in</span> entries <span class=\"pysrc-keyword\">if</span> pron[0] == <span class=\"pysrc-string\">'N'</span> <span class=\"pysrc-keyword\">and</span> w[0] != <span class=\"pysrc-string\">'n'</span>))\n",
      "<span class=\"pysrc-output\">['gn', 'kn', 'mn', 'pn']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>The phones contain digits to represent\n",
      "primary stress (<tt class=\"doctest\"><span class=\"pre\">1</span></tt>), secondary stress (<tt class=\"doctest\"><span class=\"pre\">2</span></tt>) and no stress (<tt class=\"doctest\"><span class=\"pre\">0</span></tt>).\n",
      "As our final example, we define a function to extract the stress digits\n",
      "and then scan our lexicon to find words having a particular stress pattern.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">def</span> <span class=\"pysrc-defname\">stress</span>(pron):\n",
      "<span class=\"pysrc-more\">... </span>    return [char <span class=\"pysrc-keyword\">for</span> phone <span class=\"pysrc-keyword\">in</span> pron <span class=\"pysrc-keyword\">for</span> char <span class=\"pysrc-keyword\">in</span> phone <span class=\"pysrc-keyword\">if</span> char.isdigit()]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[w <span class=\"pysrc-keyword\">for</span> w, pron <span class=\"pysrc-keyword\">in</span> entries <span class=\"pysrc-keyword\">if</span> stress(pron) == [<span class=\"pysrc-string\">'0'</span>, <span class=\"pysrc-string\">'1'</span>, <span class=\"pysrc-string\">'0'</span>, <span class=\"pysrc-string\">'2'</span>, <span class=\"pysrc-string\">'0'</span>]]\n",
      "<span class=\"pysrc-output\">['abbreviated', 'abbreviated', 'abbreviating', 'accelerated', 'accelerating',</span>\n",
      "<span class=\"pysrc-output\">'accelerator', 'accelerators', 'accentuated', 'accentuating', 'accommodated',</span>\n",
      "<span class=\"pysrc-output\">'accommodating', 'accommodative', 'accumulated', 'accumulating', 'accumulative', ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[w <span class=\"pysrc-keyword\">for</span> w, pron <span class=\"pysrc-keyword\">in</span> entries <span class=\"pysrc-keyword\">if</span> stress(pron) == [<span class=\"pysrc-string\">'0'</span>, <span class=\"pysrc-string\">'2'</span>, <span class=\"pysrc-string\">'0'</span>, <span class=\"pysrc-string\">'1'</span>, <span class=\"pysrc-string\">'0'</span>]]\n",
      "<span class=\"pysrc-output\">['abbreviation', 'abbreviations', 'abomination', 'abortifacient', 'abortifacients',</span>\n",
      "<span class=\"pysrc-output\">'academicians', 'accommodation', 'accommodations', 'accreditation', 'accreditations',</span>\n",
      "<span class=\"pysrc-output\">'accumulation', 'accumulations', 'acetylcholine', 'acetylcholine', 'adjudication', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\">A subtlety of the above program is that our\n",
      "user-defined function <tt class=\"doctest\"><span class=\"pre\">stress()</span></tt> is invoked inside the condition of\n",
      "a list comprehension.  There is also a doubly-nested <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">for</span></span></tt> loop.\n",
      "There's a lot going on here and you might want\n",
      "to return to this once you've had more experience using list comprehensions.</p>\n",
      "</div>\n",
      "<p>We can use a conditional frequency distribution to help us find minimally-contrasting\n",
      "sets of words.  Here we find all the <span class=\"example\">p</span>-words consisting of three sounds <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#p3-words\"><span id=\"ref-p3-words\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>,\n",
      "and group them according to their first and last sounds <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#group-first-last\"><span id=\"ref-group-first-last\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>p3 = [(pron[0]+<span class=\"pysrc-string\">'-'</span>+pron[2], word) <a name=\"group-first-last\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-group-first-last\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-more\">... </span>      <span class=\"pysrc-keyword\">for</span> (word, pron) <span class=\"pysrc-keyword\">in</span> entries\n",
      "<span class=\"pysrc-more\">... </span>      <span class=\"pysrc-keyword\">if</span> pron[0] == <span class=\"pysrc-string\">'P'</span> <span class=\"pysrc-keyword\">and</span> len(pron) == 3] <a name=\"p3-words\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-p3-words\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>cfd = nltk.ConditionalFreqDist(p3)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> template <span class=\"pysrc-keyword\">in</span> sorted(cfd.conditions()):\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">if</span> len(cfd[template]) &gt; 10:\n",
      "<span class=\"pysrc-more\">... </span>        words = sorted(cfd[template])\n",
      "<span class=\"pysrc-more\">... </span>        wordstring = <span class=\"pysrc-string\">' '</span>.join(words)\n",
      "<span class=\"pysrc-more\">... </span>        <span class=\"pysrc-keyword\">print</span>(template, wordstring[:70] + <span class=\"pysrc-string\">\"...\"</span>)\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">P-CH patch pautsch peach perch petsch petsche piche piech pietsch pitch pit...</span>\n",
      "<span class=\"pysrc-output\">P-K pac pack paek paik pak pake paque peak peake pech peck peek perc perk ...</span>\n",
      "<span class=\"pysrc-output\">P-L pahl pail paille pal pale pall paul paule paull peal peale pearl pearl...</span>\n",
      "<span class=\"pysrc-output\">P-N paign pain paine pan pane pawn payne peine pen penh penn pin pine pinn...</span>\n",
      "<span class=\"pysrc-output\">P-P paap paape pap pape papp paup peep pep pip pipe pipp poop pop pope pop...</span>\n",
      "<span class=\"pysrc-output\">P-R paar pair par pare parr pear peer pier poor poore por pore porr pour...</span>\n",
      "<span class=\"pysrc-output\">P-S pace pass pasts peace pearse pease perce pers perse pesce piece piss p...</span>\n",
      "<span class=\"pysrc-output\">P-T pait pat pate patt peart peat peet peete pert pet pete pett piet piett...</span>\n",
      "<span class=\"pysrc-output\">P-UW1 peru peugh pew plew plue prew pru prue prugh pshew pugh...</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Rather than iterating over the whole dictionary, we can also access it\n",
      "by looking up particular words.  We will use Python's dictionary data\n",
      "structure, which we will study systematically in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch05.html#sec-dictionaries\">3</a>.\n",
      "We look up a dictionary by giving its name followed by a <a name=\"key_index_term\"><span class=\"termdef\">key</span>\n",
      "(such as the word <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'fire'</span></span></tt>) inside square brackets </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#dict-key\"><span id=\"ref-dict-key\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>prondict = nltk.corpus.cmudict.dict()\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>prondict[<span class=\"pysrc-string\">'fire'</span>] <a name=\"dict-key\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-dict-key\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">[['F', 'AY1', 'ER0'], ['F', 'AY1', 'R']]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>prondict[<span class=\"pysrc-string\">'blog'</span>] <a name=\"dict-key-error\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-dict-key-error\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-except\">Traceback (most recent call last):</span>\n",
      "<span class=\"pysrc-except\">  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;</span>\n",
      "<span class=\"pysrc-except\">KeyError: 'blog'</span>\n",
      "<span class=\"pysrc-except\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>prondict[<span class=\"pysrc-string\">'blog'</span>] = [[<span class=\"pysrc-string\">'B'</span>, <span class=\"pysrc-string\">'L'</span>, <span class=\"pysrc-string\">'AA1'</span>, <span class=\"pysrc-string\">'G'</span>]] <a name=\"dict-assign\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-dict-assign\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>prondict[<span class=\"pysrc-string\">'blog'</span>]\n",
      "<span class=\"pysrc-output\">[['B', 'L', 'AA1', 'G']]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>If we try to look up a non-existent key <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#dict-key-error\"><span id=\"ref-dict-key-error\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>, we get a <tt class=\"doctest\"><span class=\"pre\">KeyError</span></tt>.\n",
      "This is similar to what happens when we index a list with an\n",
      "integer that is too large, producing an <tt class=\"doctest\"><span class=\"pre\">IndexError</span></tt>.\n",
      "The word <span class=\"example\">blog</span> is missing from the pronouncing dictionary,\n",
      "so we tweak our version by assigning a value for this key <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#dict-assign\"><span id=\"ref-dict-assign\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></span></a>\n",
      "(this has no effect on the NLTK corpus; next time we access it,\n",
      "<span class=\"example\">blog</span> will still be absent).</p>\n",
      "<p>We can use any lexical resource to process a text, e.g., to filter out words having\n",
      "some lexical property (like nouns), or mapping every word of the text.\n",
      "For example, the following text-to-speech function looks up each word\n",
      "of the text in the pronunciation dictionary.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>text = [<span class=\"pysrc-string\">'natural'</span>, <span class=\"pysrc-string\">'language'</span>, <span class=\"pysrc-string\">'processing'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[ph <span class=\"pysrc-keyword\">for</span> w <span class=\"pysrc-keyword\">in</span> text <span class=\"pysrc-keyword\">for</span> ph <span class=\"pysrc-keyword\">in</span> prondict[w][0]]\n",
      "<span class=\"pysrc-output\">['N', 'AE1', 'CH', 'ER0', 'AH0', 'L', 'L', 'AE1', 'NG', 'G', 'W', 'AH0', 'JH',</span>\n",
      "<span class=\"pysrc-output\">'P', 'R', 'AA1', 'S', 'EH0', 'S', 'IH0', 'NG']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<!-- [Summary of tabular lexicons; forward reference to discussion about processing CSV files] -->\n",
      "</div>\n",
      "<div class=\"section\" id=\"comparative-wordlists\">\n",
      "<h2>4.3&nbsp;&nbsp;&nbsp;Comparative Wordlists</h2>\n",
      "<p>Another example of a tabular lexicon is the <a name=\"comparative_wordlist_index_term\"><span class=\"termdef\">comparative wordlist</span>.\n",
      "NLTK includes so-called </a><a name=\"swadesh_wordlists_index_term\"><span class=\"termdef\">Swadesh wordlists</span>, lists of about 200 common words\n",
      "in several languages.  The languages are identified using an ISO 639 two-letter code.</a></p><a name=\"swadesh_wordlists_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> swadesh\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>swadesh.fileids()\n",
      "<span class=\"pysrc-output\">['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr', 'it', 'la', 'mk',</span>\n",
      "<span class=\"pysrc-output\">'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>swadesh.words(<span class=\"pysrc-string\">'en'</span>)\n",
      "<span class=\"pysrc-output\">['I', 'you (singular), thou', 'he', 'we', 'you (plural)', 'they', 'this', 'that',</span>\n",
      "<span class=\"pysrc-output\">'here', 'there', 'who', 'what', 'where', 'when', 'how', 'not', 'all', 'many', 'some',</span>\n",
      "<span class=\"pysrc-output\">'few', 'other', 'one', 'two', 'three', 'four', 'five', 'big', 'long', 'wide', ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"swadesh_wordlists_index_term\">We can access cognate words from multiple languages using the <tt class=\"doctest\"><span class=\"pre\">entries()</span></tt> method,\n",
      "specifying a list of languages.  With one further step we can convert this into\n",
      "a simple dictionary (we'll learn about <tt class=\"doctest\"><span class=\"pre\">dict()</span></tt> in </a><a class=\"reference external\" href=\"https://www.nltk.org/book/ch05.html#sec-dictionaries\">3</a>).</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>fr2en = swadesh.entries([<span class=\"pysrc-string\">'fr'</span>, <span class=\"pysrc-string\">'en'</span>])\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>fr2en\n",
      "<span class=\"pysrc-output\">[('je', 'I'), ('tu, vous', 'you (singular), thou'), ('il', 'he'), ...]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate = dict(fr2en)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate[<span class=\"pysrc-string\">'chien'</span>]\n",
      "<span class=\"pysrc-output\">'dog'</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate[<span class=\"pysrc-string\">'jeter'</span>]\n",
      "<span class=\"pysrc-output\">'throw'</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We can make our simple translator more useful by adding other source languages.\n",
      "Let's get the German-English and Spanish-English pairs, convert each to a\n",
      "dictionary using <tt class=\"doctest\"><span class=\"pre\">dict()</span></tt>, then <em>update</em> our original <tt class=\"doctest\"><span class=\"pre\">translate</span></tt> dictionary\n",
      "with these additional mappings:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>de2en = swadesh.entries([<span class=\"pysrc-string\">'de'</span>, <span class=\"pysrc-string\">'en'</span>])    <span class=\"pysrc-comment\"># German-English</span>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>es2en = swadesh.entries([<span class=\"pysrc-string\">'es'</span>, <span class=\"pysrc-string\">'en'</span>])    <span class=\"pysrc-comment\"># Spanish-English</span>\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate.update(dict(de2en))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate.update(dict(es2en))\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate[<span class=\"pysrc-string\">'Hund'</span>]\n",
      "<span class=\"pysrc-output\">'dog'</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>translate[<span class=\"pysrc-string\">'perro'</span>]\n",
      "<span class=\"pysrc-output\">'dog'</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We can compare words in various Germanic and Romance languages:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>languages = [<span class=\"pysrc-string\">'en'</span>, <span class=\"pysrc-string\">'de'</span>, <span class=\"pysrc-string\">'nl'</span>, <span class=\"pysrc-string\">'es'</span>, <span class=\"pysrc-string\">'fr'</span>, <span class=\"pysrc-string\">'pt'</span>, <span class=\"pysrc-string\">'la'</span>]\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> i <span class=\"pysrc-keyword\">in</span> [139, 140, 141, 142]:\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(swadesh.entries(languages)[i])\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">('say', 'sagen', 'zeggen', 'decir', 'dire', 'dizer', 'dicere')</span>\n",
      "<span class=\"pysrc-output\">('sing', 'singen', 'zingen', 'cantar', 'chanter', 'cantar', 'canere')</span>\n",
      "<span class=\"pysrc-output\">('play', 'spielen', 'spelen', 'jugar', 'jouer', 'jogar, brincar', 'ludere')</span>\n",
      "<span class=\"pysrc-output\">('float', 'schweben', 'zweven', 'flotar', 'flotter', 'flutuar, boiar', 'fluctuare')</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"shoebox-and-toolbox-lexicons\">\n",
      "<h2>4.4&nbsp;&nbsp;&nbsp;Shoebox and Toolbox Lexicons</h2>\n",
      "<p>Perhaps the single most popular tool used by linguists for managing data\n",
      "is <em>Toolbox</em>, previously known as <em>Shoebox</em> since it replaces\n",
      "the field linguist's traditional shoebox full of file cards.\n",
      "Toolbox is freely downloadable from <tt class=\"doctest\"><span class=\"pre\">http://www.sil.org/computing/toolbox/</span></tt>.</p>\n",
      "<p>A Toolbox file consists of a collection of entries,\n",
      "where each entry is made up of one or more fields.\n",
      "Most fields are optional or repeatable, which means that this kind of\n",
      "lexical resource cannot be treated as a table or spreadsheet.</p>\n",
      "<p>Here is a dictionary for the Rotokas language.  We see just the first entry,\n",
      "for the word <span class=\"example\">kaa</span> meaning \"to gag\":</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> toolbox\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>toolbox.entries(<span class=\"pysrc-string\">'rotokas.dic'</span>)\n",
      "<span class=\"pysrc-output\">[('kaa', [('ps', 'V'), ('pt', 'A'), ('ge', 'gag'), ('tkp', 'nek i pas'),</span>\n",
      "<span class=\"pysrc-output\">('dcsv', 'true'), ('vx', '1'), ('sc', '???'), ('dt', '29/Oct/2005'),</span>\n",
      "<span class=\"pysrc-output\">('ex', 'Apoka ira kaaroi aioa-ia reoreopaoro.'),</span>\n",
      "<span class=\"pysrc-output\">('xp', 'Kaikai i pas long nek bilong Apoka bikos em i kaikai na toktok.'),</span>\n",
      "<span class=\"pysrc-output\">('xe', 'Apoka is gagging from food while talking.')]), ...]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Entries consist of a series of attribute-value pairs, like <tt class=\"doctest\"><span class=\"pre\">(<span class=\"pysrc-string\">'ps'</span>, <span class=\"pysrc-string\">'V'</span>)</span></tt>\n",
      "to indicate that the part-of-speech is <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'V'</span></span></tt> (verb), and <tt class=\"doctest\"><span class=\"pre\">(<span class=\"pysrc-string\">'ge'</span>, <span class=\"pysrc-string\">'gag'</span>)</span></tt>\n",
      "to indicate that the gloss-into-English is <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'gag'</span></span></tt>.\n",
      "The last three pairs contain\n",
      "an example sentence in Rotokas and its translations into Tok Pisin and English.</p>\n",
      "<p>The loose structure of Toolbox files makes it hard for us to do much more with them\n",
      "at this stage.  XML provides a powerful way to process this kind of corpus and\n",
      "we will return to this topic in <a class=\"reference external\" href=\"https://www.nltk.org/book/ch11.html#chap-data\">11.</a>.</p>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\">The Rotokas language is spoken on the island of Bougainville, Papua New Guinea.\n",
      "This lexicon was contributed to NLTK by Stuart Robinson.\n",
      "Rotokas is notable for having an inventory of just 12 phonemes (contrastive sounds),\n",
      "<tt class=\"doctest\"><span class=\"pre\">http://en.wikipedia.org/wiki/Rotokas_language</span></tt></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"wordnet\">\n",
      "<span id=\"sec-wordnet\"></span><h1>5&nbsp;&nbsp;&nbsp;WordNet</h1>\n",
      "<!-- XXX Can we do a better job of explaining what's going on in WordNet? Trying to\n",
      "process the combination of WN's unfamiliar organization and datastructures, plus\n",
      "the notation, plus the NLTK interface, imposes a very heavy cognitive load.\n",
      "E.g. this whole WN  notion is pretty bizarre in some ways: \"entity ``car.n.01`` is called a `synset`:dt:,\" -->\n",
      "<p><a name=\"wordnet_index_term\"><span class=\"term\">WordNet</span> is a semantically-oriented dictionary of English,\n",
      "similar to a traditional thesaurus but with a richer structure.\n",
      "NLTK includes the English WordNet, with 155,287 words\n",
      "and 117,659 synonym sets.  We'll begin by\n",
      "looking at synonyms and how they are accessed in WordNet.</a></p><a name=\"wordnet_index_term\">\n",
      "</a><div class=\"section\" id=\"senses-and-synonyms\"><a name=\"wordnet_index_term\">\n",
      "<h2>5.1&nbsp;&nbsp;&nbsp;Senses and Synonyms</h2>\n",
      "<!-- senses in order of decreasing frequency? -->\n",
      "<!-- how to access frequency? -->\n",
      "</a><p><a name=\"wordnet_index_term\">Consider the sentence in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#ex-car1\">(1a)</a>.\n",
      "If we replace the word <span class=\"example\">motorcar</span> in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#ex-car1\">(1a)</a> by <span class=\"example\">automobile</span>,\n",
      "to get <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#ex-car2\">(1b)</a>, the meaning of the sentence stays pretty much the same:</p>\n",
      "<p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"example\">\n",
      "  <tbody><tr valign=\"top\"><td width=\"30\" align=\"right\">(1)</td><td width=\"15\"></td><td><span class=\"target\" id=\"ex-car1\"></span><p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"example\">\n",
      "  <tbody><tr valign=\"top\"><td width=\"30\" align=\"right\">a.</td><td width=\"15\"></td><td>Benz is credited with the invention of the motorcar.</td></tr></tbody></table></p>\n",
      "<span class=\"target\" id=\"ex-car2\"></span><p><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"example\">\n",
      "  <tbody><tr valign=\"top\"><td width=\"30\" align=\"right\">b.</td><td width=\"15\"></td><td>Benz is credited with the invention of the automobile.</td></tr></tbody></table></p>\n",
      "</td></tr></tbody></table></p>\n",
      "<p>Since everything else in the sentence has remained unchanged, we can\n",
      "conclude that the words <span class=\"example\">motorcar</span> and <span class=\"example\">automobile</span> have the\n",
      "same meaning, i.e. they are <a name=\"synonyms_index_term\"><span class=\"termdef\">synonyms</span>.  We can explore these\n",
      "words with the help of WordNet:</a></p><a name=\"synonyms_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">from</span> nltk.corpus <span class=\"pysrc-keyword\">import</span> wordnet <span class=\"pysrc-keyword\">as</span> wn\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synsets(<span class=\"pysrc-string\">'motorcar'</span>)\n",
      "<span class=\"pysrc-output\">[Synset('car.n.01')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"synonyms_index_term\">Thus, <span class=\"example\">motorcar</span> has just one possible meaning and it is identified as <tt class=\"doctest\"><span class=\"pre\">car.n.01</span></tt>,\n",
      "the first noun sense of <span class=\"example\">car</span>.  The entity <tt class=\"doctest\"><span class=\"pre\">car.n.01</span></tt> is called a </a><a name=\"synset_index_term\"><span class=\"termdef\">synset</span>,\n",
      "or \"synonym set\", a collection of synonymous words (or \"lemmas\"):</a></p><a name=\"synset_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'car.n.01'</span>).lemma_names()\n",
      "<span class=\"pysrc-output\">['car', 'auto', 'automobile', 'machine', 'motorcar']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Each word of a synset can have several meanings, e.g., <span class=\"example\">car</span> can also signify\n",
      "a train carriage, a gondola, or an elevator car.  However, we are only interested\n",
      "in the single meaning that is common to all words of the above synset.  Synsets\n",
      "also come with a prose definition and some example sentences:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'car.n.01'</span>).definition()\n",
      "<span class=\"pysrc-output\">'a motor vehicle with four wheels; usually propelled by an internal combustion engine'</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'car.n.01'</span>).examples()\n",
      "<span class=\"pysrc-output\">['he needs a car to get to work']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"synset_index_term\">Although definitions help humans to understand the intended meaning of a synset,\n",
      "the <span class=\"emphasis\">words</span> of the synset are often more useful for our programs.\n",
      "To eliminate ambiguity, we will identify these words as\n",
      "<tt class=\"doctest\"><span class=\"pre\">car.n.01.automobile</span></tt>, <tt class=\"doctest\"><span class=\"pre\">car.n.01.motorcar</span></tt>, and so on.\n",
      "This pairing of a synset with a word is called a lemma.\n",
      "We can get all the lemmas for a given synset </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#get-lemmas\"><span id=\"ref-get-lemmas\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></span></a>,\n",
      "look up a particular lemma <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#lookup-lemma\"><span id=\"ref-lookup-lemma\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></span></a>,\n",
      "get the synset corresponding to a lemma <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#get-synset\"><span id=\"ref-get-synset\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></span></a>,\n",
      "and get the \"name\" of a lemma <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#get-name\"><span id=\"ref-get-name\"><img src=\"./kadai3_files/callout4.gif\" alt=\"[4]\" class=\"callout\"></span></a>:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'car.n.01'</span>).lemmas() <a name=\"get-lemmas\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-get-lemmas\"><img src=\"./kadai3_files/callout1.gif\" alt=\"[1]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">[Lemma('car.n.01.car'), Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'),</span>\n",
      "<span class=\"pysrc-output\">Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'car.n.01.automobile'</span>) <a name=\"lookup-lemma\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-lookup-lemma\"><img src=\"./kadai3_files/callout2.gif\" alt=\"[2]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">Lemma('car.n.01.automobile')</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'car.n.01.automobile'</span>).synset() <a name=\"get-synset\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-get-synset\"><img src=\"./kadai3_files/callout3.gif\" alt=\"[3]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">Synset('car.n.01')</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'car.n.01.automobile'</span>).name() <a name=\"get-name\"></a><a href=\"https://www.nltk.org/book/ch02.html#ref-get-name\"><img src=\"./kadai3_files/callout4.gif\" alt=\"[4]\" class=\"callout\"></a>\n",
      "<span class=\"pysrc-output\">'automobile'</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Unlike the word <span class=\"example\">motorcar</span>, which is unambiguous and has one\n",
      "synset, the word <span class=\"example\">car</span> is ambiguous, having five synsets:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synsets(<span class=\"pysrc-string\">'car'</span>)\n",
      "<span class=\"pysrc-output\">[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'),</span>\n",
      "<span class=\"pysrc-output\">Synset('cable_car.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> synset <span class=\"pysrc-keyword\">in</span> wn.synsets(<span class=\"pysrc-string\">'car'</span>):\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(synset.lemma_names())\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">['car', 'auto', 'automobile', 'machine', 'motorcar']</span>\n",
      "<span class=\"pysrc-output\">['car', 'railcar', 'railway_car', 'railroad_car']</span>\n",
      "<span class=\"pysrc-output\">['car', 'gondola']</span>\n",
      "<span class=\"pysrc-output\">['car', 'elevator_car']</span>\n",
      "<span class=\"pysrc-output\">['cable_car', 'car']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>For convenience, we can access all the lemmas involving the word <span class=\"example\">car</span>\n",
      "as follows.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemmas(<span class=\"pysrc-string\">'car'</span>)\n",
      "<span class=\"pysrc-output\">[Lemma('car.n.01.car'), Lemma('car.n.02.car'), Lemma('car.n.03.car'),</span>\n",
      "<span class=\"pysrc-output\">Lemma('car.n.04.car'), Lemma('cable_car.n.01.car')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Your Turn:</strong>\n",
      "Write down all the senses of the word <span class=\"example\">dish</span> that you can think of.  Now, explore this\n",
      "word with the help of WordNet, using the same operations we used above.</p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"the-wordnet-hierarchy\">\n",
      "<h2>5.2&nbsp;&nbsp;&nbsp;The WordNet Hierarchy</h2>\n",
      "<p>WordNet synsets correspond to abstract concepts, and they don't always\n",
      "have corresponding words in English.  These concepts are linked together in a hierarchy.\n",
      "Some concepts are very general, such as <em>Entity</em>, <em>State</em>, <em>Event</em> — these are called\n",
      "<a name=\"unique_beginners_index_term\"><span class=\"termdef\">unique beginners</span> or root synsets.  Others, such as <em>gas guzzler</em> and\n",
      "<em>hatchback</em>, are much more specific. A small portion of a concept\n",
      "hierarchy is illustrated in </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-wn-hierarchy\">5.1</a>.</p>\n",
      "<span class=\"target\" id=\"fig-wn-hierarchy\"></span><div class=\"figure\" id=\"fig-wn-hierarchy\">\n",
      "<img alt=\"../images/wordnet-hierarchy.png\" src=\"./kadai3_files/wordnet-hierarchy.png\" style=\"width: 451.25px; height: 245.0px;\">\n",
      "<p class=\"caption\"><span class=\"caption-label\">Figure 5.1</span>: Fragment of WordNet Concept Hierarchy: nodes correspond to synsets;\n",
      "edges indicate the hypernym/hyponym relation, i.e. the relation between\n",
      "superordinate and subordinate concepts.</p>\n",
      "</div>\n",
      "<p>WordNet makes it easy to navigate between concepts.\n",
      "For example, given a concept like <em>motorcar</em>,\n",
      "we can look at the concepts that are more specific;\n",
      "the (immediate) <a name=\"hyponyms_index_term\"><span class=\"termdef\">hyponyms</span>.</a></p><a name=\"hyponyms_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>motorcar = wn.synset(<span class=\"pysrc-string\">'car.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>types_of_motorcar = motorcar.hyponyms()\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>types_of_motorcar[0]\n",
      "<span class=\"pysrc-output\">Synset('ambulance.n.01')</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>sorted(lemma.name() <span class=\"pysrc-keyword\">for</span> synset <span class=\"pysrc-keyword\">in</span> types_of_motorcar <span class=\"pysrc-keyword\">for</span> lemma <span class=\"pysrc-keyword\">in</span> synset.lemmas())\n",
      "<span class=\"pysrc-output\">['Model_T', 'S.U.V.', 'SUV', 'Stanley_Steamer', 'ambulance', 'beach_waggon',</span>\n",
      "<span class=\"pysrc-output\">'beach_wagon', 'bus', 'cab', 'compact', 'compact_car', 'convertible',</span>\n",
      "<span class=\"pysrc-output\">'coupe', 'cruiser', 'electric', 'electric_automobile', 'electric_car',</span>\n",
      "<span class=\"pysrc-output\">'estate_car', 'gas_guzzler', 'hack', 'hardtop', 'hatchback', 'heap',</span>\n",
      "<span class=\"pysrc-output\">'horseless_carriage', 'hot-rod', 'hot_rod', 'jalopy', 'jeep', 'landrover',</span>\n",
      "<span class=\"pysrc-output\">'limo', 'limousine', 'loaner', 'minicar', 'minivan', 'pace_car', 'patrol_car',</span>\n",
      "<span class=\"pysrc-output\">'phaeton', 'police_car', 'police_cruiser', 'prowl_car', 'race_car', 'racer',</span>\n",
      "<span class=\"pysrc-output\">'racing_car', 'roadster', 'runabout', 'saloon', 'secondhand_car', 'sedan',</span>\n",
      "<span class=\"pysrc-output\">'sport_car', 'sport_utility', 'sport_utility_vehicle', 'sports_car', 'squad_car',</span>\n",
      "<span class=\"pysrc-output\">'station_waggon', 'station_wagon', 'stock_car', 'subcompact', 'subcompact_car',</span>\n",
      "<span class=\"pysrc-output\">'taxi', 'taxicab', 'tourer', 'touring_car', 'two-seater', 'used-car', 'waggon',</span>\n",
      "<span class=\"pysrc-output\">'wagon']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We can also navigate up the hierarchy by visiting hypernyms.  Some words\n",
      "have multiple paths, because they can be classified in more than one way.\n",
      "There are two paths between <tt class=\"doctest\"><span class=\"pre\">car.n.01</span></tt> and <tt class=\"doctest\"><span class=\"pre\">entity.n.01</span></tt> because\n",
      "<tt class=\"doctest\"><span class=\"pre\">wheeled_vehicle.n.01</span></tt> can be classified as both a vehicle and a container.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>motorcar.hypernyms()\n",
      "<span class=\"pysrc-output\">[Synset('motor_vehicle.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>paths = motorcar.hypernym_paths()\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>len(paths)\n",
      "<span class=\"pysrc-output\">2</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[synset.name() <span class=\"pysrc-keyword\">for</span> synset <span class=\"pysrc-keyword\">in</span> paths[0]]\n",
      "<span class=\"pysrc-output\">['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'artifact.n.01',</span>\n",
      "<span class=\"pysrc-output\">'instrumentality.n.03', 'container.n.01', 'wheeled_vehicle.n.01',</span>\n",
      "<span class=\"pysrc-output\">'self-propelled_vehicle.n.01', 'motor_vehicle.n.01', 'car.n.01']</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>[synset.name() <span class=\"pysrc-keyword\">for</span> synset <span class=\"pysrc-keyword\">in</span> paths[1]]\n",
      "<span class=\"pysrc-output\">['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'artifact.n.01',</span>\n",
      "<span class=\"pysrc-output\">'instrumentality.n.03', 'conveyance.n.03', 'vehicle.n.01', 'wheeled_vehicle.n.01',</span>\n",
      "<span class=\"pysrc-output\">'self-propelled_vehicle.n.01', 'motor_vehicle.n.01', 'car.n.01']</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>We can get the most general hypernyms (or root hypernyms) of\n",
      "a synset as follows:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>motorcar.root_hypernyms()\n",
      "<span class=\"pysrc-output\">[Synset('entity.n.01')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\"><strong>Your Turn:</strong>\n",
      "Try out NLTK's convenient graphical WordNet browser: <tt class=\"doctest\"><span class=\"pre\">nltk.app.wordnet()</span></tt>.\n",
      "Explore the WordNet hierarchy by following the hypernym and hyponym links.</p>\n",
      "</div>\n",
      "</a></div><a name=\"hyponyms_index_term\">\n",
      "</a><div class=\"section\" id=\"more-lexical-relations\"><a name=\"hyponyms_index_term\">\n",
      "<h2>5.3&nbsp;&nbsp;&nbsp;More Lexical Relations</h2>\n",
      "</a><p><a name=\"hyponyms_index_term\">Hypernyms and hyponyms are called </a><a name=\"lexical_relations_index_term\"><span class=\"termdef\">lexical relations</span> because they relate one\n",
      "synset to another.  These two relations navigate up and down the \"is-a\" hierarchy.\n",
      "Another important way to navigate the WordNet network is from items to their\n",
      "components (</a><a name=\"meronyms_index_term\"><span class=\"termdef\">meronyms</span>) or to the things they are contained in (</a><a name=\"holonyms_index_term\"><span class=\"termdef\">holonyms</span>).\n",
      "For example, the parts of a <span class=\"example\">tree</span> are its <span class=\"example\">trunk</span>, <span class=\"example\">crown</span>, and so on;\n",
      "the <tt class=\"doctest\"><span class=\"pre\">part_meronyms()</span></tt>.\n",
      "The <em>substance</em> a tree is made of includes <span class=\"example\">heartwood</span> and <span class=\"example\">sapwood</span>;\n",
      "the <tt class=\"doctest\"><span class=\"pre\">substance_meronyms()</span></tt>.\n",
      "A collection of trees forms a <span class=\"example\">forest</span>; the <tt class=\"doctest\"><span class=\"pre\">member_holonyms()</span></tt>:</a></p><a name=\"holonyms_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'tree.n.01'</span>).part_meronyms()\n",
      "<span class=\"pysrc-output\">[Synset('burl.n.02'), Synset('crown.n.07'), Synset('limb.n.02'),</span>\n",
      "<span class=\"pysrc-output\">Synset('stump.n.01'), Synset('trunk.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'tree.n.01'</span>).substance_meronyms()\n",
      "<span class=\"pysrc-output\">[Synset('heartwood.n.01'), Synset('sapwood.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'tree.n.01'</span>).member_holonyms()\n",
      "<span class=\"pysrc-output\">[Synset('forest.n.01')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>To see just how intricate things can get, consider the word <span class=\"example\">mint</span>, which\n",
      "has several closely-related senses.  We can see that <tt class=\"doctest\"><span class=\"pre\">mint.n.04</span></tt> is part of\n",
      "<tt class=\"doctest\"><span class=\"pre\">mint.n.02</span></tt> and the substance from which <tt class=\"doctest\"><span class=\"pre\">mint.n.05</span></tt> is made.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span><span class=\"pysrc-keyword\">for</span> synset <span class=\"pysrc-keyword\">in</span> wn.synsets(<span class=\"pysrc-string\">'mint'</span>, wn.NOUN):\n",
      "<span class=\"pysrc-more\">... </span>    <span class=\"pysrc-keyword\">print</span>(synset.name() + <span class=\"pysrc-string\">':'</span>, synset.definition())\n",
      "<span class=\"pysrc-more\">...</span>\n",
      "<span class=\"pysrc-output\">batch.n.02: (often followed by `of') a large number or amount or extent</span>\n",
      "<span class=\"pysrc-output\">mint.n.02: any north temperate plant of the genus Mentha with aromatic leaves and</span>\n",
      "<span class=\"pysrc-output\">           small mauve flowers</span>\n",
      "<span class=\"pysrc-output\">mint.n.03: any member of the mint family of plants</span>\n",
      "<span class=\"pysrc-output\">mint.n.04: the leaves of a mint plant used fresh or candied</span>\n",
      "<span class=\"pysrc-output\">mint.n.05: a candy that is flavored with a mint oil</span>\n",
      "<span class=\"pysrc-output\">mint.n.06: a plant where money is coined by authority of the government</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'mint.n.04'</span>).part_holonyms()\n",
      "<span class=\"pysrc-output\">[Synset('mint.n.02')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'mint.n.04'</span>).substance_holonyms()\n",
      "<span class=\"pysrc-output\">[Synset('mint.n.05')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"holonyms_index_term\">There are also relationships between verbs.  For example, the act of <span class=\"example\">walking</span> involves the act of <span class=\"example\">stepping</span>,\n",
      "so walking </a><a name=\"entails_index_term\"><span class=\"termdef\">entails</span> stepping.  Some verbs have multiple entailments:</a></p><a name=\"entails_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'walk.v.01'</span>).entailments()\n",
      "<span class=\"pysrc-output\">[Synset('step.v.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'eat.v.01'</span>).entailments()\n",
      "<span class=\"pysrc-output\">[Synset('chew.v.01'), Synset('swallow.v.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'tease.v.03'</span>).entailments()\n",
      "<span class=\"pysrc-output\">[Synset('arouse.v.07'), Synset('disappoint.v.01')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "</a><p><a name=\"entails_index_term\">Some lexical relationships hold between lemmas, e.g., </a><a name=\"antonymy_index_term\"><span class=\"termdef\">antonymy</span>:</a></p><a name=\"antonymy_index_term\">\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'supply.n.02.supply'</span>).antonyms()\n",
      "<span class=\"pysrc-output\">[Lemma('demand.n.02.demand')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'rush.v.01.rush'</span>).antonyms()\n",
      "<span class=\"pysrc-output\">[Lemma('linger.v.04.linger')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'horizontal.a.01.horizontal'</span>).antonyms()\n",
      "<span class=\"pysrc-output\">[Lemma('inclined.a.02.inclined'), Lemma('vertical.a.01.vertical')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.lemma(<span class=\"pysrc-string\">'staccato.r.01.staccato'</span>).antonyms()\n",
      "<span class=\"pysrc-output\">[Lemma('legato.r.01.legato')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>You can see the lexical relations, and the other methods defined\n",
      "on a synset, using <tt class=\"doctest\"><span class=\"pre\">dir()</span></tt>, for example: <tt class=\"doctest\"><span class=\"pre\">dir(wn.synset(<span class=\"pysrc-string\">'harmony.n.02'</span>))</span></tt>.</p>\n",
      "</a></div><a name=\"antonymy_index_term\">\n",
      "</a><div class=\"section\" id=\"semantic-similarity\"><a name=\"antonymy_index_term\">\n",
      "<h2>5.4&nbsp;&nbsp;&nbsp;Semantic Similarity</h2>\n",
      "<!-- TODO: discuss WSD, mention Semcor, give pine cone example -->\n",
      "<p>We have seen that synsets are linked by a complex network of\n",
      "lexical relations.  Given a particular synset, we can traverse\n",
      "the WordNet network to find synsets with related meanings.\n",
      "Knowing which words are semantically related\n",
      "is useful for indexing a collection of texts, so\n",
      "that a search for a general term like <span class=\"example\">vehicle</span> will match documents\n",
      "containing specific terms like <span class=\"example\">limousine</span>.</p>\n",
      "</a><p><a name=\"antonymy_index_term\">Recall that each synset has one or more hypernym paths that link it\n",
      "to a root hypernym such as <tt class=\"doctest\"><span class=\"pre\">entity.n.01</span></tt>.\n",
      "Two synsets linked to the same root may have several hypernyms in common\n",
      "(cf </a><a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-wn-hierarchy\">5.1</a>).\n",
      "If two synsets share a very specific hypernym — one that is low\n",
      "down in the hypernym hierarchy — they must be closely related.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right = wn.synset(<span class=\"pysrc-string\">'right_whale.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>orca = wn.synset(<span class=\"pysrc-string\">'orca.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>minke = wn.synset(<span class=\"pysrc-string\">'minke_whale.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>tortoise = wn.synset(<span class=\"pysrc-string\">'tortoise.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>novel = wn.synset(<span class=\"pysrc-string\">'novel.n.01'</span>)\n",
      "<span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.lowest_common_hypernyms(minke)\n",
      "<span class=\"pysrc-output\">[Synset('baleen_whale.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.lowest_common_hypernyms(orca)\n",
      "<span class=\"pysrc-output\">[Synset('whale.n.02')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.lowest_common_hypernyms(tortoise)\n",
      "<span class=\"pysrc-output\">[Synset('vertebrate.n.01')]</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.lowest_common_hypernyms(novel)\n",
      "<span class=\"pysrc-output\">[Synset('entity.n.01')]</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Of course we know that <span class=\"example\">whale</span> is very specific (and <span class=\"example\">baleen whale</span> even more so),\n",
      "while <span class=\"example\">vertebrate</span> is more general and <span class=\"example\">entity</span> is completely general.\n",
      "We can quantify this concept of generality by looking up the depth of each synset:</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'baleen_whale.n.01'</span>).min_depth()\n",
      "<span class=\"pysrc-output\">14</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'whale.n.02'</span>).min_depth()\n",
      "<span class=\"pysrc-output\">13</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'vertebrate.n.01'</span>).min_depth()\n",
      "<span class=\"pysrc-output\">8</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>wn.synset(<span class=\"pysrc-string\">'entity.n.01'</span>).min_depth()\n",
      "<span class=\"pysrc-output\">0</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<p>Similarity measures have been defined over the collection of WordNet synsets\n",
      "which incorporate the above insight.  For example,\n",
      "<tt class=\"doctest\"><span class=\"pre\">path_similarity</span></tt> assigns a score in the range <tt class=\"doctest\"><span class=\"pre\">0</span></tt>–<tt class=\"doctest\"><span class=\"pre\">1</span></tt> based on the shortest path that connects the concepts in the hypernym\n",
      "hierarchy (<tt class=\"doctest\"><span class=\"pre\">-1</span></tt> is returned in those cases where a path cannot be\n",
      "found).  Comparing a synset with itself will return <tt class=\"doctest\"><span class=\"pre\">1</span></tt>.\n",
      "Consider the following similarity scores, relating <span class=\"example\">right whale</span>\n",
      "to <span class=\"example\">minke whale</span>, <span class=\"example\">orca</span>, <span class=\"example\">tortoise</span>, and <span class=\"example\">novel</span>.\n",
      "Although the numbers won't mean much, they decrease as\n",
      "we move away from the semantic space of sea creatures to inanimate objects.</p>\n",
      "<div class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"doctest\" width=\"95%\">\n",
      "<tbody><tr><td class=\"doctest\">\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n",
      "<tbody><tr><td width=\"1\" class=\"copybar\" onclick=\"javascript:copy_doctest_to_clipboard(this.nextSibling);\">&nbsp;</td>\n",
      "<td class=\"pysrc\"><pre class=\"doctest\"><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.path_similarity(minke)\n",
      "<span class=\"pysrc-output\">0.25</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.path_similarity(orca)\n",
      "<span class=\"pysrc-output\">0.16666666666666666</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.path_similarity(tortoise)\n",
      "<span class=\"pysrc-output\">0.07692307692307693</span>\n",
      "<span class=\"pysrc-output\"></span><span class=\"pysrc-prompt\">&gt;&gt;&gt; </span>right.path_similarity(novel)\n",
      "<span class=\"pysrc-output\">0.043478260869565216</span></pre>\n",
      "</td>\n",
      "</tr></tbody></table></td></tr>\n",
      "</tbody></table></div>\n",
      "<div class=\"admonition note\">\n",
      "<p class=\"first admonition-title\">Note</p>\n",
      "<p class=\"last\">Several other similarity measures are available; you can type <tt class=\"doctest\"><span class=\"pre\">help(wn)</span></tt>\n",
      "for more information.  NLTK also includes VerbNet, a hierarhical verb lexicon linked to WordNet.\n",
      "It can be accessed with <tt class=\"doctest\"><span class=\"pre\">nltk.corpus.verbnet</span></tt>.</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section\" id=\"summary\">\n",
      "<h1>6&nbsp;&nbsp;&nbsp;Summary</h1>\n",
      "<ul class=\"simple\">\n",
      "<li>A text corpus is a large, structured collection of texts.  NLTK comes with many corpora,\n",
      "e.g., the Brown Corpus, <tt class=\"doctest\"><span class=\"pre\">nltk.corpus.brown</span></tt>.</li>\n",
      "<li>Some text corpora are categorized, e.g., by genre or topic; sometimes the\n",
      "categories of a corpus overlap each other.</li>\n",
      "<li>A conditional frequency distribution is a collection of frequency distributions,\n",
      "each one for a different condition.  They can be used for counting word frequencies,\n",
      "given a context or a genre.</li>\n",
      "<li>Python programs more than a few lines long should be entered using a text editor,\n",
      "saved to a file with a <tt class=\"doctest\"><span class=\"pre\">.py</span></tt> extension, and accessed using an <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span></span></tt> statement.</li>\n",
      "<li>Python functions permit you to associate a name with a particular block of code,\n",
      "and re-use that code as often as necessary.</li>\n",
      "<li>Some functions, known as \"methods\", are associated with an object and we give the object\n",
      "name followed by a period followed by the function, like this: <tt class=\"doctest\"><span class=\"pre\">x.funct(y)</span></tt>,\n",
      "e.g., <tt class=\"doctest\"><span class=\"pre\">word.isalpha()</span></tt>.</li>\n",
      "<li>To find out about some variable <tt class=\"doctest\"><span class=\"pre\">v</span></tt>,\n",
      "type <tt class=\"doctest\"><span class=\"pre\">help(v)</span></tt> in the Python interactive interpreter to read the help entry for this kind of object.</li>\n",
      "<li>WordNet is a semantically-oriented dictionary of English, consisting of synonym sets — or synsets —\n",
      "and organized into a network.</li>\n",
      "<li>Some functions are not available by default, but must be accessed using\n",
      "Python's <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span></span></tt> statement.</li>\n",
      "</ul>\n",
      "</div>\n",
      "<div class=\"section\" id=\"further-reading\">\n",
      "<span id=\"sec-further-reading-corpora\"></span><h1>7&nbsp;&nbsp;&nbsp;Further Reading</h1>\n",
      "<p>Extra materials for this chapter are posted at <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/</span></tt>, including links to freely\n",
      "available resources on the web.  The corpus methods are summarized in the\n",
      "Corpus HOWTO, at <tt class=\"doctest\"><span class=\"pre\">http://nltk.org/howto</span></tt>, and documented extensively in the online API documentation.</p>\n",
      "<p>Significant sources of published corpora are the <span class=\"example\">Linguistic Data Consortium</span> (LDC) and\n",
      "the <span class=\"example\">European Language Resources Agency</span> (ELRA).  Hundreds of annotated text and speech\n",
      "corpora are available in dozens of languages.  Non-commercial licences permit the data to\n",
      "be used in teaching and research.  For some corpora, commercial licenses are also available\n",
      "(but for a higher fee).</p>\n",
      "<p>A good tool for creating annotated text corpora is called <span class=\"emphasis\">Brat</span>,\n",
      "and available from <tt class=\"doctest\"><span class=\"pre\">http://brat.nlplab.org/</span></tt>.</p>\n",
      "<p>These and many other language resources have been documented using OLAC Metadata, and can\n",
      "be searched via the OLAC homepage at <tt class=\"doctest\"><span class=\"pre\">http://www.language-archives.org/</span></tt>.  <span class=\"emphasis\">Corpora List</span> is a mailing list\n",
      "for discussions about corpora, and you can find resources by searching the list archives\n",
      "or posting to the list.\n",
      "The most complete inventory of the world's languages is <em>Ethnologue</em>, <tt class=\"doctest\"><span class=\"pre\">http://www.ethnologue.com/</span></tt>.\n",
      "Of 7,000 languages, only a few dozen have substantial digital resources suitable for\n",
      "use in NLP.</p>\n",
      "<p>This chapter has touched on the field of <a name=\"corpus_linguistics_index_term\"><span class=\"termdef\">Corpus Linguistics</span>.  Other useful books in this\n",
      "area include </a><a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#biber1998\" id=\"id1\">(Biber, Conrad, &amp; Reppen, 1998)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#mcenery2006\" id=\"id2\">(McEnery, 2006)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#meyer2002\" id=\"id3\">(Meyer, 2002)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#sampson2005\" id=\"id4\">(Sampson &amp; McCarthy, 2005)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#scott2006\" id=\"id5\">(Scott &amp; Tribble, 2006)</a>.\n",
      "Further readings in quantitative data analysis in linguistics are:\n",
      "<a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#baayen2008\" id=\"id6\">(Baayen, 2008)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#gries2009\" id=\"id7\">(Gries, 2009)</a>, <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#woods1986\" id=\"id8\">(Woods, Fletcher, &amp; Hughes, 1986)</a>.</p>\n",
      "<p>The original description of WordNet is <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#fellbaum1998\" id=\"id9\">(Fellbaum, 1998)</a>.\n",
      "Although WordNet was originally developed for research\n",
      "in psycholinguistics, it is now widely used in NLP and Information Retrieval.\n",
      "WordNets are being developed for many other languages, as documented\n",
      "at <tt class=\"doctest\"><span class=\"pre\">http://www.globalwordnet.org/</span></tt>.\n",
      "For a study of WordNet similarity measures, see <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#budanitsky2006ewb\" id=\"id10\">(Budanitsky &amp; Hirst, 2006)</a>.</p>\n",
      "<p>Other topics touched on in this chapter were phonetics and lexical semantics,\n",
      "and we refer readers to chapters 7 and 20 of <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#jurafskymartin2008\" id=\"id11\">(Jurafsky &amp; Martin, 2008)</a>.</p>\n",
      "</div>\n",
      "<div class=\"section\" id=\"exercises\">\n",
      "<h1>8&nbsp;&nbsp;&nbsp;Exercises</h1>\n",
      "<ol class=\"arabic simple\">\n",
      "<li>☼ Create a variable <tt class=\"doctest\"><span class=\"pre\">phrase</span></tt> containing a list of words.\n",
      "Review the operations described in the previous chapter, including addition,\n",
      "multiplication, indexing, slicing, and sorting.</li>\n",
      "<li>☼ Use the corpus module to explore <tt class=\"doctest\"><span class=\"pre\">austen-persuasion.txt</span></tt>.\n",
      "How many word tokens does this book have?  How many word types?</li>\n",
      "<li>☼ Use the Brown corpus reader <tt class=\"doctest\"><span class=\"pre\">nltk.corpus.brown.words()</span></tt> or the Web text corpus\n",
      "reader <tt class=\"doctest\"><span class=\"pre\">nltk.corpus.webtext.words()</span></tt> to access some sample text in two different genres.</li>\n",
      "<li>☼ Read in the texts of the <em>State of the Union</em> addresses, using the\n",
      "<tt class=\"doctest\"><span class=\"pre\">state_union</span></tt> corpus reader.  Count occurrences of <tt class=\"doctest\"><span class=\"pre\">men</span></tt>, <tt class=\"doctest\"><span class=\"pre\">women</span></tt>,\n",
      "and <tt class=\"doctest\"><span class=\"pre\">people</span></tt> in each document.  What has happened to the usage of these\n",
      "words over time?</li>\n",
      "<li>☼ Investigate the holonym-meronym relations for some nouns.\n",
      "Remember that there are three kinds of holonym-meronym relation,\n",
      "so you need to use:\n",
      "<tt class=\"doctest\"><span class=\"pre\">member_meronyms()</span></tt>, <tt class=\"doctest\"><span class=\"pre\">part_meronyms()</span></tt>, <tt class=\"doctest\"><span class=\"pre\">substance_meronyms()</span></tt>,\n",
      "<tt class=\"doctest\"><span class=\"pre\">member_holonyms()</span></tt>, <tt class=\"doctest\"><span class=\"pre\">part_holonyms()</span></tt>, and <tt class=\"doctest\"><span class=\"pre\">substance_holonyms()</span></tt>.</li>\n",
      "<li>☼ In the discussion of comparative wordlists, we created an object\n",
      "called <tt class=\"doctest\"><span class=\"pre\">translate</span></tt> which you could look up using words in both German and Spanish\n",
      "in order to get corresponding words in English.\n",
      "What problem might arise with this approach?\n",
      "Can you suggest a way to avoid this problem?</li>\n",
      "<li>☼ According to Strunk and White's <em>Elements of Style</em>,\n",
      "the word <span class=\"example\">however</span>, used at the start of a sentence,\n",
      "means \"in whatever way\" or \"to whatever extent\", and not\n",
      "\"nevertheless\".  They give this example of correct usage:\n",
      "<span class=\"example\">However you advise him, he will probably do as he thinks best.</span>\n",
      "(<tt class=\"doctest\"><span class=\"pre\">http://www.bartleby.com/141/strunk3.html</span></tt>)\n",
      "Use the concordance tool to study actual usage of this word\n",
      "in the various texts we have been considering.\n",
      "See also the <em>LanguageLog</em> posting \"Fossilized prejudices about 'however'\"\n",
      "at <tt class=\"doctest\"><span class=\"pre\">http://itre.cis.upenn.edu/~myl/languagelog/archives/001913.html</span></tt></li>\n",
      "<li>◑ Define a conditional frequency distribution over the Names corpus\n",
      "that allows you to see which <em>initial</em> letters are more frequent for males\n",
      "vs. females (cf. <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#fig-cfd-gender\">4.4</a>).</li>\n",
      "<li>◑ Pick a pair of texts and study the differences between them,\n",
      "in terms of vocabulary, vocabulary richness, genre, etc.  Can you\n",
      "find pairs of words which have quite different meanings across the\n",
      "two texts, such as <span class=\"example\">monstrous</span> in <em>Moby Dick</em> and in <em>Sense and Sensibility</em>?</li>\n",
      "<li>◑ Read the BBC News article: <em>UK's Vicky Pollards 'left behind'</em> <tt class=\"doctest\"><span class=\"pre\">http://news.bbc.co.uk/1/hi/education/6173441.stm</span></tt>.\n",
      "The article gives the following statistic about teen language:\n",
      "\"the top 20 words used, including yeah, no, but and like, account for around a third of all words.\"\n",
      "How many word types account for a third\n",
      "of all word tokens, for a variety of text sources?  What do you conclude about this statistic?\n",
      "Read more about this on <em>LanguageLog</em>, at <tt class=\"doctest\"><span class=\"pre\">http://itre.cis.upenn.edu/~myl/languagelog/archives/003993.html</span></tt>.</li>\n",
      "<li>◑ Investigate the table of modal distributions and look for other patterns.\n",
      "Try to explain them in terms of your own impressionistic understanding\n",
      "of the different genres.  Can you find other closed classes of words that\n",
      "exhibit significant differences across different genres?</li>\n",
      "<li>◑ The CMU Pronouncing Dictionary contains multiple pronunciations\n",
      "for certain words.  How many distinct words does it contain?  What fraction\n",
      "of words in this dictionary have more than one possible pronunciation?</li>\n",
      "<li>◑ What percentage of noun synsets have no hyponyms?\n",
      "You can get all noun synsets using <tt class=\"doctest\"><span class=\"pre\">wn.all_synsets(<span class=\"pysrc-string\">'n'</span>)</span></tt>.</li>\n",
      "<li>◑ Define a function <tt class=\"doctest\"><span class=\"pre\">supergloss(s)</span></tt> that takes a synset <tt class=\"doctest\"><span class=\"pre\">s</span></tt> as its argument\n",
      "and returns a string consisting of the concatenation of the definition of <tt class=\"doctest\"><span class=\"pre\">s</span></tt>, and\n",
      "the definitions of all the hypernyms and hyponyms of <tt class=\"doctest\"><span class=\"pre\">s</span></tt>.</li>\n",
      "<li>◑ Write a program to find all words that occur at least three times in the Brown Corpus.</li>\n",
      "<li>◑ Write a program to generate a table of lexical diversity scores (i.e. token/type ratios), as we saw in\n",
      "<a class=\"reference external\" href=\"https://www.nltk.org/book/ch01.html#tab-brown-types\">1.1</a>.  Include the full set of Brown Corpus genres (<tt class=\"doctest\"><span class=\"pre\">nltk.corpus.brown.categories()</span></tt>).\n",
      "Which genre has the lowest diversity (greatest number of tokens per type)?\n",
      "Is this what you would have expected?</li>\n",
      "<li>◑ Write a function that finds the 50 most frequently occurring words\n",
      "of a text that are not stopwords.</li>\n",
      "<li>◑ Write a program to print the 50 most frequent bigrams\n",
      "(pairs of adjacent words) of a text, omitting bigrams that contain stopwords.</li>\n",
      "<li>◑ Write a program to create a table of word frequencies by genre,\n",
      "like the one given in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#sec-extracting-text-from-corpora\">1</a> for modals.\n",
      "Choose your own words and try to find words whose presence\n",
      "(or absence) is typical of a genre.  Discuss your findings.</li>\n",
      "<li>◑ Write a function <tt class=\"doctest\"><span class=\"pre\">word_freq()</span></tt> that takes a word and the name of a section\n",
      "of the Brown Corpus as arguments, and computes the frequency of the word\n",
      "in that section of the corpus.</li>\n",
      "<li>◑ Write a program to guess the number of syllables contained in a text,\n",
      "making use of the CMU Pronouncing Dictionary.</li>\n",
      "<li>◑ Define a function <tt class=\"doctest\"><span class=\"pre\">hedge(text)</span></tt> which processes a\n",
      "text and produces a new version with the word\n",
      "<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-string\">'like'</span></span></tt> between every third word.</li>\n",
      "<li>★ <strong>Zipf's Law</strong>:\n",
      "Let <em>f(w)</em> be the frequency of a word <em>w</em> in free text. Suppose that\n",
      "all the words of a text are ranked according to their frequency,\n",
      "with the most frequent word first. Zipf's law states that the\n",
      "frequency of a word type is inversely proportional to its rank\n",
      "(i.e. <em>f</em> × <em>r = k</em>, for some constant <em>k</em>). For example, the 50th most\n",
      "common word type should occur three times as frequently as the\n",
      "150th most common word type.<ol class=\"loweralpha\">\n",
      "<li>Write a function to process a large text and plot word\n",
      "frequency against word rank using <tt class=\"doctest\"><span class=\"pre\">pylab.plot</span></tt>. Do\n",
      "you confirm Zipf's law? (Hint: it helps to use a logarithmic scale).\n",
      "What is going on at the extreme ends of the plotted line?</li>\n",
      "<li>Generate random text, e.g., using <tt class=\"doctest\"><span class=\"pre\">random.choice(<span class=\"pysrc-string\">\"abcdefg \"</span>)</span></tt>,\n",
      "taking care to include the space character.  You will need to\n",
      "<tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span> random</span></tt> first.  Use the string\n",
      "concatenation operator to accumulate characters into a (very)\n",
      "long string.  Then tokenize this string, and generate the Zipf\n",
      "plot as before, and compare the two plots.  What do you make of\n",
      "Zipf's Law in the light of this?</li>\n",
      "</ol>\n",
      "</li>\n",
      "<li>★ Modify the text generation program in <a class=\"reference internal\" href=\"https://www.nltk.org/book/ch02.html#code-random-text\">2.2</a> further, to\n",
      "do the following tasks:<ol class=\"loweralpha\">\n",
      "<li>Store the <em>n</em> most likely words in a list <tt class=\"doctest\"><span class=\"pre\">words</span></tt> then randomly\n",
      "choose a word from the list using <tt class=\"doctest\"><span class=\"pre\">random.choice()</span></tt>.  (You will need\n",
      "to <tt class=\"doctest\"><span class=\"pre\"><span class=\"pysrc-keyword\">import</span> random</span></tt> first.)</li>\n",
      "<li>Select a particular genre, such as a section of the Brown Corpus,\n",
      "or a genesis translation, one of the Gutenberg texts, or one of the Web texts.  Train\n",
      "the model on this corpus and get it to generate random text.  You\n",
      "may have to experiment with different start words. How intelligible\n",
      "is the text?  Discuss the strengths and weaknesses of this method of\n",
      "generating random text.</li>\n",
      "<li>Now train your system using two distinct genres and experiment\n",
      "with generating text in the hybrid genre.  Discuss your observations.</li>\n",
      "</ol>\n",
      "</li>\n",
      "<li>★ Define a function <tt class=\"doctest\"><span class=\"pre\">find_language()</span></tt> that takes a string\n",
      "as its argument, and returns a list of languages that have that\n",
      "string as a word.  Use the <tt class=\"doctest\"><span class=\"pre\">udhr</span></tt> corpus and limit your searches\n",
      "to files in the Latin-1 encoding.</li>\n",
      "<li>★ What is the branching factor of the noun hypernym hierarchy?\n",
      "I.e. for every noun synset that has hyponyms — or children in the\n",
      "hypernym hierarchy — how many do they have on average?\n",
      "You can get all noun synsets using <tt class=\"doctest\"><span class=\"pre\">wn.all_synsets(<span class=\"pysrc-string\">'n'</span>)</span></tt>.</li>\n",
      "<li>★ The polysemy of a word is the number of senses it has.\n",
      "Using WordNet, we can determine that the noun <em>dog</em> has 7 senses\n",
      "with: <tt class=\"doctest\"><span class=\"pre\">len(wn.synsets(<span class=\"pysrc-string\">'dog'</span>, <span class=\"pysrc-string\">'n'</span>))</span></tt>.\n",
      "Compute the average polysemy of nouns, verbs, adjectives and\n",
      "adverbs according to WordNet.</li>\n",
      "<li>★ Use one of the predefined similarity measures to score\n",
      "the similarity of each of the following pairs of words.\n",
      "Rank the pairs in order of decreasing similarity.\n",
      "How close is your ranking to the order given here,\n",
      "an order that was established experimentally\n",
      "by <a class=\"reference external\" href=\"https://www.nltk.org/book/bibliography.html#millercharles1998\" id=\"id12\">(Miller &amp; Charles, 1998)</a>:\n",
      "car-automobile, gem-jewel, journey-voyage, boy-lad,\n",
      "coast-shore, asylum-madhouse, magician-wizard, midday-noon,\n",
      "furnace-stove, food-fruit, bird-cock, bird-crane, tool-implement,\n",
      "brother-monk, lad-brother, crane-implement, journey-car,\n",
      "monk-oracle, cemetery-woodland, food-rooster, coast-hill,\n",
      "forest-graveyard, shore-woodland, monk-slave, coast-forest,\n",
      "lad-wizard, chord-smile, glass-magician, rooster-voyage, noon-string.</li>\n",
      "</ol>\n",
      "<!-- Footer to be used in all chapters -->\n",
      "<div class=\"admonition admonition-about-this-document\">\n",
      "<p class=\"first admonition-title\">About this document...</p>\n",
      "<p>UPDATED FOR NLTK 3.0.\n",
      "This is a chapter from <em>Natural Language Processing with Python</em>,\n",
      "by <a class=\"reference external\" href=\"http://stevenbird.net/\">Steven Bird</a>, <a class=\"reference external\" href=\"http://homepages.inf.ed.ac.uk/ewan/\">Ewan Klein</a> and <a class=\"reference external\" href=\"http://ed.loper.org/\">Edward Loper</a>,\n",
      "Copyright © 2019 the authors.\n",
      "It is distributed with the <em>Natural Language Toolkit</em> [<tt class=\"doctest\"><span class=\"pre\">http://nltk.org/</span></tt>],\n",
      "Version 3.0, under the terms of the\n",
      "<em>Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 United States License</em>\n",
      "[<a class=\"reference external\" href=\"http://creativecommons.org/licenses/by-nc-nd/3.0/us/\">http://creativecommons.org/licenses/by-nc-nd/3.0/us/</a>].</p>\n",
      "<p class=\"last\">This document was built on\n",
      "Wed  4 Sep 2019 11:40:48 ACST</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
